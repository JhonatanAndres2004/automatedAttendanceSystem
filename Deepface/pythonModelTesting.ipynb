{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from retinaface import RetinaFace\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from deepface import DeepFace\n",
    "import numpy as np\n",
    "import os\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Face Pattern Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define image to work with. It represents the real classroom photo taken with the camera\n",
    "classroomFolder=os.path.join(\"..\",\"ImagesDeepface\",\"RealClassroomPhotos\")\n",
    "#Select the model to be used for detection varying the list index\n",
    "detectors = [ \"mtcnn\",\"opencv\", \"retinaface\"]\n",
    "#Change depending on the index to be evaluates\n",
    "chosen_detector_index=2\n",
    "\n",
    "m=1\n",
    "boundingBoxDetectedFaces=[]\n",
    "\n",
    "#Iterate through all real classroom photos\n",
    "for file in os.listdir(classroomFolder):\n",
    "    camera_local_file = os.path.join(\"..\",\"ImagesDeepface\",\"RealClassroomPhotos\",file)\n",
    "    boundingBoxDetectedFacesNthImage=[]\n",
    "    image = cv2.imread(camera_local_file)\n",
    "    faces = DeepFace.extract_faces(img_path=camera_local_file, detector_backend=detectors[chosen_detector_index],enforce_detection=False)\n",
    "    #Obtain images dimensions\n",
    "    image_height, image_width, _ = image.shape\n",
    "\n",
    "    #Save the coordinates of all faces in order to paint it later\n",
    "    for i in range(len(faces)):\n",
    "        boundingBoxDetectedFacesNthImage.append((faces[i][\"facial_area\"][\"x\"],faces[i][\"facial_area\"][\"y\"],faces[i][\"facial_area\"][\"w\"],\n",
    "                                                faces[i][\"facial_area\"][\"h\"]))\n",
    "    # Draw bounding boxes for each detected face using the coordinates\n",
    "    for element in boundingBoxDetectedFacesNthImage:\n",
    "        left = element[0]\n",
    "        top = element[1]\n",
    "        width = element[2]\n",
    "        height =  element[3]\n",
    "        cv2.rectangle(\n",
    "            image, \n",
    "            (left, top), \n",
    "            (left + width, top + height), \n",
    "            (0,0,200), \n",
    "            2  \n",
    "        )\n",
    "    boundingBoxDetectedFaces.append(boundingBoxDetectedFacesNthImage)\n",
    "    # Print number of faces detected\n",
    "    print(f\"{len(boundingBoxDetectedFacesNthImage)} Faces were detected in {camera_local_file}\")\n",
    "\n",
    "    # Save the annotated image in the destinated folder\n",
    "    output_path =os.path.join(\"..\",\"ImagesDeepface\",\"Detection\",f\"Detection{detectors[chosen_detector_index]}\",f\"faces_detected_{m}.jpeg\")\n",
    "    \n",
    "    cv2.imwrite(output_path, image)\n",
    "    #Increase the photo's index\n",
    "    m=m+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_iou_detection(box1, box2):\n",
    "\n",
    "    x1, y1, w1, h1 = box1\n",
    "    x2, y2, w2, h2 = box2\n",
    "    \n",
    "    x_intersect_1 = max(x1, x2)\n",
    "    y_intersect_1 = max(y1, y2)\n",
    "    x_intersect_2 = min(x1 + w1, x2 + w2)\n",
    "    y_intersect_2 = min(y1 + h1, y2 + h2)\n",
    "    \n",
    "    if x_intersect_2 <= x_intersect_1 or y_intersect_2 <= y_intersect_1:\n",
    "        return 0.0\n",
    "    \n",
    "    area_intersect = (x_intersect_2 - x_intersect_1) * (y_intersect_2 - y_intersect_1)\n",
    "    area_box1 = w1 * h1\n",
    "    area_box2 = w2 * h2\n",
    "    \n",
    "    area_union = area_box1 + area_box2 - area_intersect\n",
    "    \n",
    "    iou = area_intersect / area_union\n",
    "    \n",
    "    return iou\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(os.path.join(\"..\",\"Data\",\"groundTruth.txt\"), \"r\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "groundTruth=ast.literal_eval(content)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "m=1\n",
    "#The N-Element contains tuples of the N-Th image with informations of students to be recognized\n",
    "tuples=[]\n",
    "for element in groundTruth:\n",
    "    i=1\n",
    "    #(f\"photo {m}-----------------------------------------\")\n",
    "    filteredgroundTruthObject=element[next(iter(element))][\"regions\"]\n",
    "    tuplesnthPhoto=[]\n",
    "    for element in filteredgroundTruthObject:\n",
    "        #print(f\"Person {i}-----\")\n",
    "        region=element[\"shape_attributes\"]\n",
    "        tuplesnthPhoto.append((region[\"x\"],region[\"y\"], region[\"width\"], region[\"height\"]))\n",
    "        i=i+1\n",
    "    tuples.append(tuplesnthPhoto)\n",
    "    m=m+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare detections and ground truth to construct the performance marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "TPTotal=0\n",
    "TNTotal=0\n",
    "FPTotal=0\n",
    "FNTotal=0\n",
    "\n",
    "for element in tuples:\n",
    "    TP=0\n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP=0\n",
    "    verifiedPredictions=0    \n",
    "    print(f\"------Results for image {i+1}------\")\n",
    "    for face in element: #Compare each face of ground truth with the predictions' array. If found, add TP, if not identified, add FN\n",
    "        found=False\n",
    "        for detectedFace in boundingBoxDetectedFaces[i]:\n",
    "            IoU=calculate_iou_detection(face, detectedFace)\n",
    "            if (IoU>=0.5):\n",
    "                found=True\n",
    "                TP=TP+1\n",
    "                verifiedPredictions=verifiedPredictions+1\n",
    "                break\n",
    "        if (found==False):\n",
    "            FN=FN+1\n",
    "    FP=FP+(len(boundingBoxDetectedFaces[i])-verifiedPredictions)\n",
    "    print(F\"TP: {TP}, TN:{TN}, FP:{FP} FN:{FN}\")\n",
    "    TPTotal=TPTotal+TP\n",
    "    TNTotal=TNTotal+TN\n",
    "    FPTotal=FPTotal+FP\n",
    "    FNTotal=FNTotal+FN\n",
    "\n",
    "\n",
    "    i=i+1\n",
    "\n",
    "print(\"----Total----\")\n",
    "print(f\"TP: {TPTotal}, TN: {TNTotal}, FP:{FPTotal},FN: {FNTotal}\")      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Face Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Number of detected faces first using the common detection chosen model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define image to work with. It represents the real classroom photo taken with the camera\n",
    "classroomFolder=os.path.join(\"..\",\"ImagesDeepface\",\"RealClassroomPhotos\")\n",
    "\n",
    "m=1\n",
    "numberOfDetectedFaces=[]\n",
    "\n",
    "#Iterate through all real classroom photos\n",
    "for file in os.listdir(classroomFolder):\n",
    "    camera_local_file = os.path.join(\"..\",\"ImagesDeepface\",\"RealClassroomPhotos\",file)\n",
    "    boundingBoxDetectedFacesNthImage=[]\n",
    "    image = cv2.imread(camera_local_file)\n",
    "    faces = DeepFace.extract_faces(img_path=camera_local_file, detector_backend=\"mtcnn\")\n",
    "    #Obtain images dimensions\n",
    "    image_height, image_width, _ = image.shape\n",
    "\n",
    "    #Save the coordinates of all faces in order to paint it later\n",
    "    for i in range(len(faces)):\n",
    "        boundingBoxDetectedFacesNthImage.append((faces[i][\"facial_area\"][\"x\"],faces[i][\"facial_area\"][\"y\"],faces[i][\"facial_area\"][\"w\"],\n",
    "                                                faces[i][\"facial_area\"][\"h\"]))\n",
    "    # Draw bounding boxes for each detected face using the coordinates\n",
    "    for element in boundingBoxDetectedFacesNthImage:\n",
    "        left = element[0]\n",
    "        top = element[1]\n",
    "        width = element[2]\n",
    "        height =  element[3]\n",
    "        cv2.rectangle(\n",
    "            image, \n",
    "            (left, top), \n",
    "            (left + width, top + height), \n",
    "            (0,0,200), \n",
    "            2  \n",
    "        )\n",
    "    numberOfDetectedFaces.append(len(boundingBoxDetectedFacesNthImage))\n",
    "    # Print number of faces detected\n",
    "    print(f\"{len(boundingBoxDetectedFacesNthImage)} Faces were detected in {camera_local_file}\")\n",
    "\n",
    "    # Save the annotated image in the destinated folder\n",
    "    output_path =os.path.join(\"..\",\"ImagesDeepface\",\"Detection\",\"Detectionmtcnn\",f\"faces_detected_{m}.jpeg\")    \n",
    "    cv2.imwrite(output_path, image)\n",
    "    #Increase the photo's index\n",
    "    m=m+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "colors = [\n",
    "    (255, 0, 0),     \n",
    "    (0, 255, 0),   \n",
    "    (0, 0, 255),    \n",
    "    (255, 255, 0),  \n",
    "    (255, 0, 255),  \n",
    "    (0, 255, 255), \n",
    "    (128, 0, 0),  \n",
    "    (0, 128, 0),   \n",
    "    (0, 0, 128),   \n",
    "    (128, 128, 0),  \n",
    "    (128, 0, 128),  \n",
    "    (0, 128, 128),  \n",
    "    (64, 0, 128),   \n",
    "    (128, 128, 255), \n",
    "    (0, 255, 128), \n",
    "    (255, 128, 0),   \n",
    "    (128, 255, 128),\n",
    "    (192, 64, 64),   \n",
    "    (64, 192, 192),\n",
    "    (255, 128, 192), \n",
    "    (32, 64, 255)   \n",
    "]\n",
    "\n",
    "recognition_models=[\"ArcFace\",\"Facenet\", \"VGG-Face\"]\n",
    "chosen_model_index=2\n",
    "\n",
    "photo_index=1\n",
    "\n",
    "classroomFolder=os.path.join(\"..\",\"ImagesDeepface\",\"RealClassroomPhotos\")\n",
    "model=recognition_models[chosen_model_index]\n",
    "\n",
    "boundingBoxRecognizedFaces=[]\n",
    "#os.makedirs(output_folder, exist_ok=True)\n",
    "m=1\n",
    "for file in os.listdir(classroomFolder):\n",
    "    camera_local_file=os.path.join(\"..\",\"ImagesDeepface\",\"RealClassroomPhotos\",file)\n",
    "    #The image read of the classroom. This will be used to redraw it\n",
    "    camera_photo = cv2.imread(camera_local_file)\n",
    "    recognized_counter=0\n",
    "    k=0\n",
    "    boundingBoxRecognizedFacesithImage=[]\n",
    "\n",
    "    print(f\"Using index {photo_index}\")\n",
    "\n",
    "    if (photo_index>=1 and photo_index<=2) or  (photo_index>=23 and photo_index<=30):\n",
    "        selectedCourse=\"StudentsRobotics\"\n",
    "        student_array=[\"AlbaQuiroz\", \"AlejandroCasallas\",\"AlejandroVelasco\",\"AlexanderDominguez\",\"AndresAnillo\",\"CarlosBornacelly\",\"DavidChaparro\"\n",
    "                    ,\"EstebanToro\",\"GabrielCastanez\",\"GiohanOlivares\",\"JesusCotes\",\"JoseVilla\", \"JuanMolina\",\"ManuelRangel\",\"MariaBerdugo\",\"MariaLopez\",\n",
    "                    \"MauricioDeLaHoz\", \"SergioFonseca\",\"YordiRochel\"]    \n",
    "    elif (photo_index>=3 and photo_index<=5) or (photo_index>=8 and photo_index<=14):\n",
    "        selectedCourse=\"StudentsElectronicDesign1\"\n",
    "        student_array=[\"AllysonSalom\", \"AngieValencia\",\"DanielDelgado\",\"DiegoGomez\", \"DylanDeOro\",\"FelipeOspino\",\"HabidAbdala\",\"JuanLozano\",\"WilmanDaza\"]\n",
    "\n",
    "    elif (photo_index>=6 and photo_index<=7) or  (photo_index>=15 and photo_index<=22):\n",
    "        selectedCourse=\"StudentsElectronicDesign2\"\n",
    "        student_array=[\"AliRada\",\"AndreaQuintero\",\"AndresFabregas\",\"AndresNarvaez\",\"BrayanRubiano\",\"DiegoGomez\",\"EdwinUtria\",\"GabrielaBecerra\",\n",
    "                    \"JuanHernandez\",\"JuanQuintero\",\"JuanSanchez\",\"LucianaDeLaRosa\",\"MariaFerrer\",\"MayraCarreno\",\n",
    "                    \"OctavioMorales\",\"SamirBarcelo\",\"SteevenBallena\"]\n",
    "\n",
    "\n",
    "\n",
    "    for student_name in student_array:\n",
    "        student_photo_path=os.path.join(\"..\",\"ImagesDeepface\",selectedCourse,f\"{student_name}.jpeg\")\n",
    "        result = DeepFace.verify(\n",
    "                    img1_path=student_photo_path, #individual\n",
    "                    img2_path=camera_local_file,\n",
    "                    model_name=model,\n",
    "                    detector_backend=\"mtcnn\",\n",
    "                    enforce_detection=False\n",
    "                    )\n",
    "        coordinatesOfGroupPhoto=result[\"facial_areas\"][\"img2\"]\n",
    "        x=coordinatesOfGroupPhoto[\"x\"]\n",
    "        y=coordinatesOfGroupPhoto[\"y\"]\n",
    "        h=coordinatesOfGroupPhoto[\"h\"]\n",
    "        w=coordinatesOfGroupPhoto[\"w\"]\n",
    "\n",
    "            # Cargar la imagen\n",
    "        if camera_photo is None:\n",
    "            raise FileNotFoundError(f\"No se pudo cargar la imagen: {classroomFolder}\")\n",
    "\n",
    "        # Dibujar el rectángulo\n",
    "        if str(result[\"verified\"])==\"True\":\n",
    "            x, y, w, h = coordinatesOfGroupPhoto[\"x\"], coordinatesOfGroupPhoto[\"y\"], coordinatesOfGroupPhoto[\"w\"], coordinatesOfGroupPhoto[\"h\"]\n",
    "            cv2.rectangle(camera_photo, (x, y), (x + w, y + h), colors[k], 2)  \n",
    "            padding = 5 \n",
    "            text_box_height = 25  \n",
    "            # Add text for each box\n",
    "            cv2.putText(camera_photo, f\"{student_name}\", (x + 10, y - padding - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, colors[k], 1)\n",
    "            print(f\"{student_name} was recognized in photo {m}\")\n",
    "            recognized_counter=recognized_counter+1\n",
    "\n",
    "            boundingBoxRecognizedFacesithImage.append((student_name,x,y,h,w))\n",
    "\n",
    "        else:\n",
    "            print(f\"{student_name} was NOT recognized in photo {m}\")\n",
    "            boundingBoxRecognizedFacesithImage.append((student_name,0,0,0,0))\n",
    "        k=k+1\n",
    "    boundingBoxRecognizedFaces.append(boundingBoxRecognizedFacesithImage)\n",
    "\n",
    "\n",
    "    output_path = os.path.join(\"..\",\"ImagesDeepface\",\"Recognition\",f\"Recognition{model}\",f\"faces_in_classroom_{m}_{recognized_counter}.jpeg\")\n",
    "        # Guardar la imagen modificada\n",
    "    cv2.imwrite(output_path, camera_photo)\n",
    "    print(f\"Imagen guardada en: {output_path}\")\n",
    "    m=m+1\n",
    "    photo_index=photo_index+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"\n",
    "    Calculate IoU between 2 boxes.\n",
    "    box1, box2: tuples like (x, y, width, height)\n",
    "    return IoU value that ranges from 0 to 1\n",
    "    \"\"\"\n",
    "    name1,x1, y1, w1, h1 = box1\n",
    "    name2, x2, y2, w2, h2 = box2\n",
    "    \n",
    "    x_intersect_1 = max(x1, x2)\n",
    "    y_intersect_1 = max(y1, y2)\n",
    "    x_intersect_2 = min(x1 + w1, x2 + w2)\n",
    "    y_intersect_2 = min(y1 + h1, y2 + h2)\n",
    "    \n",
    "    if x_intersect_2 <= x_intersect_1 or y_intersect_2 <= y_intersect_1:\n",
    "        return 0.0\n",
    "    \n",
    "    area_intersect = (x_intersect_2 - x_intersect_1) * (y_intersect_2 - y_intersect_1)\n",
    "    area_box1 = w1 * h1\n",
    "    area_box2 = w2 * h2\n",
    "    \n",
    "    area_union = area_box1 + area_box2 - area_intersect\n",
    "    \n",
    "    iou = area_intersect / area_union\n",
    "    \n",
    "    return iou\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define tuples from baseline (Manual correction and verificatio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"..\",\"Data\",\"faceGallery.txt\"), \"r\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "faceGallery=ast.literal_eval(content)\n",
    "\n",
    "\n",
    "m=1\n",
    "#The N-Element contains tuples of the N-Th image with informations of students to be recognized\n",
    "tuples=[]\n",
    "for element in faceGallery:\n",
    "    i=1\n",
    "    #(f\"photo {m}-----------------------------------------\")\n",
    "    filteredFaceGalleryObject=element[next(iter(element))][\"regions\"]\n",
    "    tuplesnthPhoto=[]\n",
    "    for element in filteredFaceGalleryObject:\n",
    "        #print(f\"Person {i}-----\")\n",
    "        region=element[\"shape_attributes\"]\n",
    "        identity=element[\"region_attributes\"]\n",
    "        #print(f\"x = {region[\"x\"]} \\ny = {region[\"y\"]} \\nwidth = {region[\"width\"]}\\nheight = {region[\"height\"]} \\nidentifier = {identity[\"name\"]}\")\n",
    "        tuplesnthPhoto.append((identity[\"name\"],region[\"x\"],region[\"y\"], region[\"width\"], region[\"height\"]))\n",
    "        i=i+1\n",
    "    tuples.append(tuplesnthPhoto)\n",
    "    m=m+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate through the base line and compare it to the results obtained by Deepface's models. Then calculate TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It searchs based on face gallery/Base Line: It compares my definition of the existance of specific students and compares it to the found studens\n",
    "#The result wouldn't be affected if the search direction is reversed\n",
    "\n",
    "i=0\n",
    "#Loop through all the photos\n",
    "\n",
    "TPTotal=0\n",
    "TNTotal=0\n",
    "FPTotal=0\n",
    "FNTotal=0\n",
    "\n",
    "for photoObject in tuples:\n",
    "    print(f\"Results for photo {i+1}\")\n",
    "    TP=0\n",
    "    TN=0\n",
    "    FP=0\n",
    "    FN=0\n",
    "    #Obtain the array of faces recognized with Rekognition in that photo\n",
    "    tuplesToCompare=boundingBoxRecognizedFaces[i]\n",
    "\n",
    "    listOfNamesBaseline=[]\n",
    "    for element in photoObject:\n",
    "        listOfNamesBaseline.append(element[0])\n",
    "\n",
    "    listOfNamesModel=[]\n",
    "    for element in tuplesToCompare:\n",
    "        listOfNamesModel.append(element[0])\n",
    "\n",
    "\n",
    "    for element in photoObject:\n",
    "        if(element[0] in listOfNamesModel):\n",
    "            for identity in tuplesToCompare:\n",
    "                IoU=calculate_iou(element,identity)\n",
    "                #print(f\"{element} compared with {identity}\")\n",
    "\n",
    "                #Case True Positive: Identity and bounding box match\n",
    "                if(IoU>=0.4 and element[0]==identity[0]):\n",
    "                    TP=TP+1\n",
    "\n",
    "                #Case False Positive: no identity match, however, the bounding boxes are similar\n",
    "                if(IoU>=0.4 and element[0]!=identity[0]):\n",
    "                    FP=FP+1\n",
    "                #Case True Negative: No bounding box match. However, the identity is different\n",
    "                if(IoU<0.4 and element[0]!=identity[0]):\n",
    "                    TN=TN+1\n",
    "                #Case False Negative: The identity matches. However, bonding boxes do not correspond\n",
    "                if(IoU<0.4 and element[0]==identity[0]):\n",
    "                    FN=FN+1 \n",
    "            TN=TN+numberOfDetectedFaces[i]-len(listOfNamesModel)\n",
    "        else:\n",
    "            FN=FN+1\n",
    "            TN=TN+numberOfDetectedFaces[i]-1\n",
    "            print(f\"{element[0]} not in model's list and adds 1 FN and {len(listOfNamesBaseline)-1} TN\")\n",
    "    TPTotal=TPTotal+TP\n",
    "    TNTotal=TNTotal+TN\n",
    "    FPTotal=FPTotal+FP\n",
    "    FNTotal=FNTotal+FN\n",
    "\n",
    "    print(f\"TP : {TP} \\nTN : {TN} \\nFP : {FP} \\nFN : {FN}\")\n",
    "    i=i+1\n",
    "\n",
    "print(\"----Total----\")\n",
    "print(f\"TP: {TPTotal}, TN: {TNTotal}, FP:{FPTotal},FN: {FNTotal}\")      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematical metrics for analizing facial similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean,cosine\n",
    "\n",
    "#Obtain the analysis of the image\n",
    "embedding1=DeepFace.represent(img_path=\"single2.jpeg\",model_name=\"ArcFace\", detector_backend=\"retinaface\")\n",
    "embedding2=DeepFace.represent(img_path=\"single11.jpeg\",model_name=\"ArcFace\", detector_backend=\"retinaface\")\n",
    "\n",
    "#Extract the multi-dimensional vector only\n",
    "embedding1Vector1=np.array(embedding1[0][\"embedding\"])\n",
    "embedding1Vector2=embedding2[0][\"embedding\"]\n",
    "\n",
    "def cosine_similarity(embedding1, embedding2):\n",
    "    dot_product = np.dot(embedding1, embedding2)\n",
    "    norm1 = np.linalg.norm(embedding1)\n",
    "    norm2 = np.linalg.norm(embedding2)\n",
    "    similarity = dot_product / (norm1 * norm2)\n",
    "    return similarity\n",
    "\n",
    "print(\"Cosine similarity is \"+ str(cosine_similarity(embedding1Vector1,embedding1Vector2)))\n",
    "\n",
    "def euclidean_distance(embedding1,embedding2):\n",
    "    return euclidean(embedding1,embedding2)\n",
    "\n",
    "print(\"Euclidean distance is \"+ str(euclidean_distance(embedding1Vector1,embedding1Vector2)))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
