{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from retinaface import RetinaFace\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from deepface import DeepFace\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Face Pattern Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 Faces were detected in C:\\Users\\User\\Desktop\\FinalProject\\ImagesDeepface\\RealClassroomPhotos\\classroom1.jpeg\n",
      "14 Faces were detected in C:\\Users\\User\\Desktop\\FinalProject\\ImagesDeepface\\RealClassroomPhotos\\classroom2.jpeg\n"
     ]
    }
   ],
   "source": [
    "#Define image to work with. It represents the real classroom photo taken with the camera\n",
    "classroomFolder=r\"C:\\Users\\User\\Desktop\\FinalProject\\ImagesDeepface\\RealClassroomPhotos\"\n",
    "#Select the model to be used for detection varying the list index\n",
    "detectors = [ \"mtcnn\",\"opencv\", \"retinaface\"]\n",
    "#Change depending on the index to be evaluates\n",
    "chosen_detector_index=2\n",
    "\n",
    "m=1\n",
    "#Iterate through all real classroom photos\n",
    "for file in os.listdir(classroomFolder):\n",
    "    facesCoordinatesList=[]\n",
    "    camera_local_file = rf'C:\\Users\\User\\Desktop\\FinalProject\\ImagesDeepface\\RealClassroomPhotos\\{file}' \n",
    "\n",
    "    image = cv2.imread(camera_local_file)\n",
    "    faces = DeepFace.extract_faces(img_path=camera_local_file, detector_backend=detectors[2])\n",
    "    #Obtain images dimensions\n",
    "    image_height, image_width, _ = image.shape\n",
    "\n",
    "    #Save the coordinates of all faces in order to paint it later\n",
    "    for i in range(len(faces)):\n",
    "        facesCoordinatesList.append(faces[i][\"facial_area\"])\n",
    "    # Draw bounding boxes for each detected face using the coordinates\n",
    "    for element in facesCoordinatesList:\n",
    "        left = element[\"x\"]\n",
    "        top = element[\"y\"]\n",
    "        width = element[\"w\"]\n",
    "        height =  element[\"h\"]\n",
    "        cv2.rectangle(\n",
    "            image, \n",
    "            (left, top), \n",
    "            (left + width, top + height), \n",
    "            (0,0,200), \n",
    "            2  \n",
    "        )\n",
    "\n",
    "    # Print number of faces detected\n",
    "    print(f\"{len(facesCoordinatesList)} Faces were detected in {camera_local_file}\")\n",
    "\n",
    "    # Save the annotated image in the destinated folder\n",
    "    output_path = rf\"C:\\Users\\User\\Desktop\\FinalProject\\ImagesDeepface\\Detection\\Detection{detectors[chosen_detector_index]}\\faces_detected_{m}.jpeg\"\n",
    "    \n",
    "    cv2.imwrite(output_path, image)\n",
    "    #Increase the photo's index\n",
    "    m=m+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YordiRochel was NOT recognized in photo 1\n",
      "MariaBerdugo was NOT recognized in photo 1\n",
      "AlbaQuiroz was NOT recognized in photo 1\n",
      "GiohanOlivares was recognized in photo 1\n",
      "JesusCotes was NOT recognized in photo 1\n",
      "Imagen guardada en: C:\\Users\\User\\Desktop\\FinalProject\\ImagesDeepface\\Recognition\\RecognitionFacenet\\faces_in_classroom1_1.jpg\n",
      "YordiRochel was NOT recognized in photo 2\n",
      "MariaBerdugo was NOT recognized in photo 2\n",
      "AlbaQuiroz was NOT recognized in photo 2\n",
      "GiohanOlivares was NOT recognized in photo 2\n",
      "JesusCotes was NOT recognized in photo 2\n",
      "Imagen guardada en: C:\\Users\\User\\Desktop\\FinalProject\\ImagesDeepface\\Recognition\\RecognitionFacenet\\faces_in_classroom2_0.jpg\n"
     ]
    }
   ],
   "source": [
    "#student_names_array=[\"AlejandroCallasas\", \"AndresAnillo\",\"DiegoGomez\",\"GabrielCastanez\", \"MauricioDeLaHoz\",\"YordiRochel\", \"MariaBerdugo\",\"AlbaQuiroz\",\"GiohanOlivares\",\"JesusCotes\"]\n",
    "#colors=[(0, 200, 0),(200,0,0),(0,0,0), (0,0,255), (150,150,0),(0,150,150),(100,20,60),(20,60,100),(60,100,20),(255,255,255)]\n",
    "student_names_array=[\"YordiRochel\", \"MariaBerdugo\",\"AlbaQuiroz\",\"GiohanOlivares\",\"JesusCotes\"]\n",
    "colors=[(0, 200, 0),(200,0,0),(0,0,0), (0,0,255), (150,150,0)]\n",
    "\n",
    "\n",
    "recognition_models=[\"ArcFace\",\"Facenet\", \"VGG-Face\"]\n",
    "chosen_model_index=1\n",
    "\n",
    "classroomFolder=r\"C:\\Users\\User\\Desktop\\FinalProject\\ImagesDeepface\\RealClassroomPhotos\"\n",
    "model=recognition_models[chosen_model_index]\n",
    "\n",
    "boundingBoxRecognizedFaces=[]\n",
    "#os.makedirs(output_folder, exist_ok=True)\n",
    "m=1\n",
    "for file in os.listdir(classroomFolder):\n",
    "    camera_local_file=rf\"C:\\Users\\User\\Desktop\\FinalProject\\ImagesDeepface\\RealClassroomPhotos\\{file}\"\n",
    "    #The image read of the classroom. This will be used to redraw it\n",
    "    camera_photo = cv2.imread(camera_local_file)\n",
    "    recognized_counter=0\n",
    "    k=0\n",
    "    boundingBoxRecognizedFacesithImage=[]\n",
    "\n",
    "    for student_name in student_names_array:\n",
    "        student_photo_path=rf\"C:\\Users\\User\\Desktop\\FinalProject\\ImagesDeepface\\Students\\{student_name}.jpeg\"\n",
    "\n",
    "        result = DeepFace.verify(\n",
    "                    img1_path=student_photo_path, #individual\n",
    "                    img2_path=camera_local_file,\n",
    "                    model_name=model,\n",
    "                    detector_backend=\"mtcnn\",\n",
    "                    enforce_detection=False\n",
    "                    )\n",
    "        coordinatesOfGroupPhoto=result[\"facial_areas\"][\"img2\"]\n",
    "        x=coordinatesOfGroupPhoto[\"x\"]\n",
    "        y=coordinatesOfGroupPhoto[\"y\"]\n",
    "        h=coordinatesOfGroupPhoto[\"h\"]\n",
    "        w=coordinatesOfGroupPhoto[\"w\"]\n",
    "\n",
    "\n",
    "            # Cargar la imagen\n",
    "        if camera_photo is None:\n",
    "            raise FileNotFoundError(f\"No se pudo cargar la imagen: {classroomFolder}\")\n",
    "\n",
    "        # Dibujar el rect치ngulo\n",
    "        if str(result[\"verified\"])==\"True\":\n",
    "            x, y, w, h = coordinatesOfGroupPhoto[\"x\"], coordinatesOfGroupPhoto[\"y\"], coordinatesOfGroupPhoto[\"w\"], coordinatesOfGroupPhoto[\"h\"]\n",
    "            cv2.rectangle(camera_photo, (x, y), (x + w, y + h), colors[k], 2)  # Color verde, grosor 2\n",
    "            padding = 5  # Espacio entre el rect치ngulo y el cuadro de texto\n",
    "            text_box_height = 25  # Altura del cuadro de texto\n",
    "            # Agregar texto dentro del recuadro de texto\n",
    "            cv2.putText(camera_photo, f\"{student_name}\", (x + 10, y - padding - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, colors[k], 1)\n",
    "            print(f\"{student_name} was recognized in photo {m}\")\n",
    "            recognized_counter=recognized_counter+1\n",
    "\n",
    "            boundingBoxRecognizedFacesithImage.append((student_name,x,y,h,w))\n",
    "\n",
    "        else:\n",
    "            print(f\"{student_name} was NOT recognized in photo {m}\")\n",
    "            boundingBoxRecognizedFacesithImage.append((student_name,0,0,0,0))\n",
    "        k=k+1\n",
    "    boundingBoxRecognizedFaces.append(boundingBoxRecognizedFacesithImage)\n",
    "\n",
    "\n",
    "    output_path = rf\"C:\\Users\\User\\Desktop\\FinalProject\\ImagesDeepface\\Recognition\\Recognition{model}\\faces_in_classroom{m}_{recognized_counter}.jpg\"\n",
    "        # Guardar la imagen modificada\n",
    "    cv2.imwrite(output_path, camera_photo)\n",
    "    print(f\"Imagen guardada en: {output_path}\")\n",
    "    m=m+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('YordiRochel', 0, 0, 0, 0),\n",
       " ('MariaBerdugo', 0, 0, 0, 0),\n",
       " ('AlbaQuiroz', 0, 0, 0, 0),\n",
       " ('GiohanOlivares', 0, 0, 0, 0),\n",
       " ('JesusCotes', 0, 0, 0, 0)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"\n",
    "    Calculate IoU between 2 boxes.\n",
    "    box1, box2: tuples like (x, y, width, height)\n",
    "    return IoU value that ranges from 0 to 1\n",
    "    \"\"\"\n",
    "    # Extraer coordenadas\n",
    "    name1,x1, y1, w1, h1 = box1\n",
    "    name2, x2, y2, w2, h2 = box2\n",
    "    \n",
    "    # Calcular coordenadas de la intersecci칩n\n",
    "    x_intersect_1 = max(x1, x2)\n",
    "    y_intersect_1 = max(y1, y2)\n",
    "    x_intersect_2 = min(x1 + w1, x2 + w2)\n",
    "    y_intersect_2 = min(y1 + h1, y2 + h2)\n",
    "    \n",
    "    # Comprobar si hay intersecci칩n\n",
    "    if x_intersect_2 <= x_intersect_1 or y_intersect_2 <= y_intersect_1:\n",
    "        return 0.0\n",
    "    \n",
    "    # Calcular 치reas\n",
    "    area_intersect = (x_intersect_2 - x_intersect_1) * (y_intersect_2 - y_intersect_1)\n",
    "    area_box1 = w1 * h1\n",
    "    area_box2 = w2 * h2\n",
    "    \n",
    "    # Calcular uni칩n\n",
    "    area_union = area_box1 + area_box2 - area_intersect\n",
    "    \n",
    "    # Calcular IoU\n",
    "    iou = area_intersect / area_union\n",
    "    \n",
    "    return iou\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define tuples from baseline (Manual correction and verificatio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('AlejandroCallasas', 733, 392, 31, 44),\n",
       "  ('AndresAnillo', 153, 475, 45, 46),\n",
       "  ('DiegoGomez', 660, 275, 20, 27),\n",
       "  ('GabrielCastanez', 13, 506, 37, 39),\n",
       "  ('MauricioDeLaHoz', 716, 348, 22, 30),\n",
       "  ('YordiRochel', 367, 421, 33, 39),\n",
       "  ('MariaBerdugo', 1155, 362, 31, 35),\n",
       "  ('AlbaQuiroz', 908, 346, 27, 31),\n",
       "  ('GiohanOlivares', 1188, 326, 32, 36),\n",
       "  ('JesusCotes', 114, 534, 44, 59)],\n",
       " [('AndresAnillo', 147, 465, 56, 60),\n",
       "  ('GabrielCastanez', 2, 496, 51, 64),\n",
       "  ('GiohanOlivares', 1206, 314, 46, 61),\n",
       "  ('GiohanOlivares', 154, 551, 55, 74),\n",
       "  ('MariaBerdugo', 1158, 347, 44, 60),\n",
       "  ('YordiRochel', 408, 415, 44, 59)]]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true=True\n",
    "faceGallery=[\n",
    "{\"classroom1.jpeg156424\":{\"filename\":\"classroom1.jpeg\",\"size\":156424,\"regions\":[{\"shape_attributes\":{\"name\":\"rect\",\"x\":733,\"y\":392,\"width\":31,\"height\":44},\"region_attributes\":{\"name\":\"AlejandroCallasas\",\"type\":\"unknown\",\"image_quality\":{\"good\":true,\"frontal\":true,\"good_illumination\":true}}},{\"shape_attributes\":{\"name\":\"rect\",\"x\":153,\"y\":475,\"width\":45,\"height\":46},\"region_attributes\":{\"name\":\"AndresAnillo\",\"type\":\"unknown\",\"image_quality\":{\"good\":true,\"frontal\":true,\"good_illumination\":true}}},{\"shape_attributes\":{\"name\":\"rect\",\"x\":660,\"y\":275,\"width\":20,\"height\":27},\"region_attributes\":{\"name\":\"DiegoGomez\",\"type\":\"unknown\",\"image_quality\":{\"good\":true,\"frontal\":true,\"good_illumination\":true}}},{\"shape_attributes\":{\"name\":\"rect\",\"x\":13,\"y\":506,\"width\":37,\"height\":39},\"region_attributes\":{\"name\":\"GabrielCastanez\",\"type\":\"unknown\",\"image_quality\":{\"good\":true,\"frontal\":true,\"good_illumination\":true}}},{\"shape_attributes\":{\"name\":\"rect\",\"x\":716,\"y\":348,\"width\":22,\"height\":30},\"region_attributes\":{\"name\":\"MauricioDeLaHoz\",\"type\":\"unknown\",\"image_quality\":{\"good\":true,\"frontal\":true,\"good_illumination\":true}}},{\"shape_attributes\":{\"name\":\"rect\",\"x\":367,\"y\":421,\"width\":33,\"height\":39},\"region_attributes\":{\"name\":\"YordiRochel\",\"type\":\"unknown\",\"image_quality\":{\"good\":true,\"frontal\":true,\"good_illumination\":true}}},{\"shape_attributes\":{\"name\":\"rect\",\"x\":1155,\"y\":362,\"width\":31,\"height\":35},\"region_attributes\":{\"name\":\"MariaBerdugo\",\"type\":\"unknown\",\"image_quality\":{\"good\":true,\"frontal\":true,\"good_illumination\":true}}},{\"shape_attributes\":{\"name\":\"rect\",\"x\":908,\"y\":346,\"width\":27,\"height\":31},\"region_attributes\":{\"name\":\"AlbaQuiroz\",\"type\":\"unknown\",\"image_quality\":{\"good\":true,\"frontal\":true,\"good_illumination\":true}}},{\"shape_attributes\":{\"name\":\"rect\",\"x\":1188,\"y\":326,\"width\":32,\"height\":36},\"region_attributes\":{\"name\":\"GiohanOlivares\",\"type\":\"unknown\",\"image_quality\":{\"good\":true,\"frontal\":true,\"good_illumination\":true}}},{\"shape_attributes\":{\"name\":\"rect\",\"x\":114,\"y\":534,\"width\":44,\"height\":59},\"region_attributes\":{\"name\":\"JesusCotes\",\"type\":\"unknown\",\"image_quality\":{\"good\":true,\"frontal\":true,\"good_illumination\":true}}}],\"file_attributes\":{\"caption\":\"\",\"public_domain\":\"no\",\"image_url\":\"\"}}},\n",
    "{\"classroom2.jpeg148639\":{\"filename\":\"classroom2.jpeg\",\"size\":148639,\"regions\":[{\"shape_attributes\":{\"name\":\"rect\",\"x\":147,\"y\":465,\"width\":56,\"height\":60},\"region_attributes\":{\"name\":\"AndresAnillo\",\"type\":\"unknown\",\"image_quality\":{\"good\":true,\"frontal\":true,\"good_illumination\":true}}},{\"shape_attributes\":{\"name\":\"rect\",\"x\":2,\"y\":496,\"width\":51,\"height\":64},\"region_attributes\":{\"name\":\"GabrielCastanez\",\"type\":\"unknown\",\"image_quality\":{\"good\":true,\"frontal\":true,\"good_illumination\":true}}},{\"shape_attributes\":{\"name\":\"rect\",\"x\":1206,\"y\":314,\"width\":46,\"height\":61},\"region_attributes\":{\"name\":\"GiohanOlivares\",\"type\":\"unknown\",\"image_quality\":{\"good\":true,\"frontal\":true,\"good_illumination\":true}}},{\"shape_attributes\":{\"name\":\"rect\",\"x\":154,\"y\":551,\"width\":55,\"height\":74},\"region_attributes\":{\"name\":\"GiohanOlivares\",\"type\":\"unknown\",\"image_quality\":{\"good\":true,\"frontal\":true,\"good_illumination\":true}}},{\"shape_attributes\":{\"name\":\"rect\",\"x\":1158,\"y\":347,\"width\":44,\"height\":60},\"region_attributes\":{\"name\":\"MariaBerdugo\",\"type\":\"unknown\",\"image_quality\":{\"good\":true,\"frontal\":true,\"good_illumination\":true}}},{\"shape_attributes\":{\"name\":\"rect\",\"x\":408,\"y\":415,\"width\":44,\"height\":59},\"region_attributes\":{\"name\":\"YordiRochel\",\"type\":\"unknown\",\"image_quality\":{\"good\":true,\"frontal\":true,\"good_illumination\":true}}}],\"file_attributes\":{\"caption\":\"\",\"public_domain\":\"no\",\"image_url\":\"\"}}}\n",
    "]\n",
    "\n",
    "m=1\n",
    "#The N-Element contains tuples of the N-Th image with informations of students to be recognized\n",
    "tuples=[]\n",
    "for element in faceGallery:\n",
    "    i=1\n",
    "    #(f\"photo {m}-----------------------------------------\")\n",
    "    filteredFaceGalleryObject=element[next(iter(element))][\"regions\"]\n",
    "    tuplesnthPhoto=[]\n",
    "    for element in filteredFaceGalleryObject:\n",
    "        #print(f\"Person {i}-----\")\n",
    "        region=element[\"shape_attributes\"]\n",
    "        identity=element[\"region_attributes\"]\n",
    "        #print(f\"x = {region[\"x\"]} \\ny = {region[\"y\"]} \\nwidth = {region[\"width\"]}\\nheight = {region[\"height\"]} \\nidentifier = {identity[\"name\"]}\")\n",
    "        tuplesnthPhoto.append((identity[\"name\"],region[\"x\"],region[\"y\"], region[\"width\"], region[\"height\"]))\n",
    "        i=i+1\n",
    "    tuples.append(tuplesnthPhoto)\n",
    "    m=m+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate through the base line and compare it to the results obtained by Deepface's models. Then calculate TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for photo 1\n",
      "AlejandroCallasas not in model's list and adds 1 FN and 9 TN\n",
      "AndresAnillo not in model's list and adds 1 FN and 9 TN\n",
      "DiegoGomez not in model's list and adds 1 FN and 9 TN\n",
      "GabrielCastanez not in model's list and adds 1 FN and 9 TN\n",
      "MauricioDeLaHoz not in model's list and adds 1 FN and 9 TN\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "TP : 1 \n",
      "TN : 65 \n",
      "FP : 0 \n",
      "FN : 9\n",
      "Results for photo 2\n",
      "AndresAnillo not in model's list and adds 1 FN and 5 TN\n",
      "GabrielCastanez not in model's list and adds 1 FN and 5 TN\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "TP : 0 \n",
      "TN : 26 \n",
      "FP : 0 \n",
      "FN : 6\n"
     ]
    }
   ],
   "source": [
    "#It searchs based on face gallery/Base Line: It compares my definition of the existance of specific students and compares it to the found studens\n",
    "#The result wouldn't be affected if the search direction is reversed\n",
    "\n",
    "i=0\n",
    "#Loop through all the photos\n",
    "for photoObject in tuples:\n",
    "    print(f\"Results for photo {i+1}\")\n",
    "    TP=0\n",
    "    TN=0\n",
    "    FP=0\n",
    "    FN=0\n",
    "    #Obtain the array of faces recognized with Rekognition in that photo\n",
    "    tuplesToCompare=boundingBoxRecognizedFaces[i]\n",
    "\n",
    "    listOfNamesBaseline=[]\n",
    "    for element in photoObject:\n",
    "        listOfNamesBaseline.append(element[0])\n",
    "\n",
    "    listOfNamesModel=[]\n",
    "    for element in tuplesToCompare:\n",
    "        listOfNamesModel.append(element[0])\n",
    "\n",
    "\n",
    "    for element in photoObject:\n",
    "        if(element[0] in listOfNamesModel):\n",
    "            for identity in tuplesToCompare:\n",
    "                print(\"-------------\")\n",
    "                IoU=calculate_iou(element,identity)\n",
    "                #print(f\"{element} compared with {identity}\")\n",
    "\n",
    "                #Case True Positive: Identity and bounding box match\n",
    "                if(IoU>=0.5 and element[0]==identity[0]):\n",
    "                    TP=TP+1\n",
    "\n",
    "                #Case False Positive: no identity match, however, the bounding boxes are similar\n",
    "                if(IoU>=0.5 and element[0]!=identity[0]):\n",
    "                    FP=FP+1\n",
    "\n",
    "                #Case True Negative: No bounding box match. However, the identity is different\n",
    "                if(IoU<0.5 and element[0]!=identity[0]):\n",
    "                    TN=TN+1\n",
    "\n",
    "                #Case False Negative: The identity matches. However, bonding boxes do not correspond\n",
    "                if(IoU<0.5 and element[0]==identity[0]):\n",
    "                    FN=FN+1 \n",
    "        else:\n",
    "            FN=FN+1\n",
    "            TN=TN+len(listOfNamesBaseline)-1\n",
    "            print(f\"{element[0]} not in model's list and adds 1 FN and {len(listOfNamesBaseline)-1} TN\")\n",
    "\n",
    "\n",
    "    print(f\"TP : {TP} \\nTN : {TN} \\nFP : {FP} \\nFN : {FN}\")\n",
    "    i=i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for photo 1\n",
      "TP : 1 \n",
      "TN : 45 \n",
      "FP : 0 \n",
      "FN : 4\n",
      "Results for photo 2\n",
      "TP : 0 \n",
      "TN : 26 \n",
      "FP : 0 \n",
      "FN : 4\n"
     ]
    }
   ],
   "source": [
    "#It searchs based on face gallery/Base Line: It compares my definition of the existance of specific students and compares it to the found studens\n",
    "#The result wouldn't be affected if the search direction is reversed\n",
    "\n",
    "i=0\n",
    "#Loop through all the photos\n",
    "for photoObject in tuples:\n",
    "    print(f\"Results for photo {i+1}\")\n",
    "    TP=0\n",
    "    TN=0\n",
    "    FP=0\n",
    "    FN=0\n",
    "    #Obtain the array of faces recognized with Rekognition in that photo\n",
    "    tuplesToCompare=boundingBoxRecognizedFaces[i]\n",
    "    #Look for every bounding box drawn in the rekognition array. Element corresponds to the drawn rectangle, identify to rekognition's precdiction\n",
    "    for element in photoObject:\n",
    "        for identity in tuplesToCompare:\n",
    "            IoU=calculate_iou(element,identity)\n",
    "            #Case True Positive: Identity and bounding box match\n",
    "            #print(f\"{element} compared with {identity}\")\n",
    "            if(IoU>=0.5 and element[0]==identity[0]):\n",
    "                TP=TP+1\n",
    "            #Case False Positive: no identity match, however, the bounding boxes are similar\n",
    "            if(IoU>=0.5 and element[0]!=identity[0]):\n",
    "                FP=TP+1\n",
    "\n",
    "            #Case True Negative: No bounding box match. However, the identity is different\n",
    "            if(IoU<0.5 and element[0]!=identity[0]):\n",
    "                TN=TN+1\n",
    "\n",
    "            #Case False Negative: The identity matches. However, bonding boxes do not correspond\n",
    "            if(IoU<0.5 and element[0]==identity[0]):\n",
    "                FN=FN+1 \n",
    "\n",
    "\n",
    "    print(f\"TP : {TP} \\nTN : {TN} \\nFP : {FP} \\nFN : {FN}\")\n",
    "    i=i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematical metrics for analizing facial similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity is 0.35477153678865364\n",
      "Euclidean distance is 3.8419692767006404\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import euclidean,cosine\n",
    "\n",
    "#Obtain the analysis of the image\n",
    "embedding1=DeepFace.represent(img_path=\"single2.jpeg\",model_name=\"ArcFace\", detector_backend=\"retinaface\")\n",
    "embedding2=DeepFace.represent(img_path=\"single11.jpeg\",model_name=\"ArcFace\", detector_backend=\"retinaface\")\n",
    "\n",
    "#Extract the multi-dimensional vector only\n",
    "embedding1Vector1=np.array(embedding1[0][\"embedding\"])\n",
    "embedding1Vector2=embedding2[0][\"embedding\"]\n",
    "\n",
    "def cosine_similarity(embedding1, embedding2):\n",
    "    dot_product = np.dot(embedding1, embedding2)\n",
    "    norm1 = np.linalg.norm(embedding1)\n",
    "    norm2 = np.linalg.norm(embedding2)\n",
    "    similarity = dot_product / (norm1 * norm2)\n",
    "    return similarity\n",
    "\n",
    "print(\"Cosine similarity is \"+ str(cosine_similarity(embedding1Vector1,embedding1Vector2)))\n",
    "\n",
    "def euclidean_distance(embedding1,embedding2):\n",
    "    return euclidean(embedding1,embedding2)\n",
    "\n",
    "print(\"Euclidean distance is \"+ str(euclidean_distance(embedding1Vector1,embedding1Vector2)))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
