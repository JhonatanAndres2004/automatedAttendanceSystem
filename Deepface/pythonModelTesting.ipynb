{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from retinaface import RetinaFace\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from deepface import DeepFace\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Face Pattern Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 Faces were detected in C:\\Users\\User\\Desktop\\FinalProject\\ImagesDeepface\\RealClassroomPhotos\\classroom1.jpeg\n",
      "14 Faces were detected in C:\\Users\\User\\Desktop\\FinalProject\\ImagesDeepface\\RealClassroomPhotos\\classroom2.jpeg\n"
     ]
    }
   ],
   "source": [
    "#Define image to work with. It represents the real classroom photo taken with the camera\n",
    "classroomFolder=r\"C:\\Users\\User\\Desktop\\FinalProject\\ImagesDeepface\\RealClassroomPhotos\"\n",
    "#Select the model to be used for detection varying the list index\n",
    "detectors = [ \"mtcnn\",\"opencv\", \"retinaface\"]\n",
    "#Change depending on the index to be evaluates\n",
    "chosen_detector_index=2\n",
    "\n",
    "m=1\n",
    "#Iterate through all real classroom photos\n",
    "for file in os.listdir(classroomFolder):\n",
    "    facesCoordinatesList=[]\n",
    "    camera_local_file = rf'C:\\Users\\User\\Desktop\\FinalProject\\ImagesDeepface\\RealClassroomPhotos\\{file}' \n",
    "\n",
    "    image = cv2.imread(camera_local_file)\n",
    "    faces = DeepFace.extract_faces(img_path=camera_local_file, detector_backend=detectors[2])\n",
    "    #Obtain images dimensions\n",
    "    image_height, image_width, _ = image.shape\n",
    "\n",
    "    #Save the coordinates of all faces in order to paint it later\n",
    "    for i in range(len(faces)):\n",
    "        facesCoordinatesList.append(faces[i][\"facial_area\"])\n",
    "    # Draw bounding boxes for each detected face using the coordinates\n",
    "    for element in facesCoordinatesList:\n",
    "        left = element[\"x\"]\n",
    "        top = element[\"y\"]\n",
    "        width = element[\"w\"]\n",
    "        height =  element[\"h\"]\n",
    "        cv2.rectangle(\n",
    "            image, \n",
    "            (left, top), \n",
    "            (left + width, top + height), \n",
    "            (0,0,200), \n",
    "            2  \n",
    "        )\n",
    "\n",
    "    # Print number of faces detected\n",
    "    print(f\"{len(facesCoordinatesList)} Faces were detected in {camera_local_file}\")\n",
    "\n",
    "    # Save the annotated image in the destinated folder\n",
    "    output_path = rf\"C:\\Users\\User\\Desktop\\FinalProject\\ImagesDeepface\\Detection\\Detection{detectors[chosen_detector_index]}\\faces_detected_{m}.jpeg\"\n",
    "    \n",
    "    cv2.imwrite(output_path, image)\n",
    "    #Increase the photo's index\n",
    "    m=m+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_names_array=[\"AlejandroCallasas\", \"AndresAnillo\",\"DiegoGomez\",\"GabrielCastanez\", \"MauricioDeLaHoz\",\"YordiRochel\", \"MariaBerdugo\",\"AlbaQuiroz\",\"GiohanOlivares\",\"JesusCotes\"]\n",
    "colors=[(0, 200, 0),(200,0,0),(0,0,0), (0,0,255), (150,150,0),(0,150,150),(100,20,60),(20,60,100),(60,100,20),(255,255,255)]\n",
    "recognition_models=[\"ArcFace\",\"Facenet\", \"VGG-Face\"]\n",
    "chosen_model_index=1\n",
    "\n",
    "classroomFolder=r\"C:\\Users\\User\\Desktop\\FinalProject\\ImagesDeepface\\RealClassroomPhotos\"\n",
    "model=recognition_models[chosen_model_index]\n",
    "\n",
    "\n",
    "#os.makedirs(output_folder, exist_ok=True)\n",
    "m=1\n",
    "for file in os.listdir(classroomFolder):\n",
    "    camera_local_file=rf\"C:\\Users\\User\\Desktop\\FinalProject\\ImagesDeepface\\RealClassroomPhotos\\{file}\"\n",
    "    #The image read of the classroom. This will be used to redraw it\n",
    "    camera_photo = cv2.imread(camera_local_file)\n",
    "    recognized_counter=0\n",
    "    k=0\n",
    "    for student_name in student_names_array:\n",
    "        student_photo_path=rf\"C:\\Users\\User\\Desktop\\FinalProject\\ImagesDeepface\\Students\\{student_name}.jpeg\"\n",
    "\n",
    "        result = DeepFace.verify(\n",
    "                    img1_path=student_photo_path, #individual\n",
    "                    img2_path=camera_local_file,\n",
    "                    model_name=model,\n",
    "                    detector_backend=\"mtcnn\",\n",
    "                    enforce_detection=False\n",
    "                    )\n",
    "        coordinatesOfGroupPhoto=result[\"facial_areas\"][\"img2\"]\n",
    "        x=coordinatesOfGroupPhoto[\"x\"]\n",
    "        y=coordinatesOfGroupPhoto[\"y\"]\n",
    "        h=coordinatesOfGroupPhoto[\"h\"]\n",
    "        w=coordinatesOfGroupPhoto[\"w\"]\n",
    "\n",
    "\n",
    "            # Cargar la imagen\n",
    "        if camera_photo is None:\n",
    "            raise FileNotFoundError(f\"No se pudo cargar la imagen: {classroomFolder}\")\n",
    "\n",
    "        # Dibujar el rectángulo\n",
    "        if str(result[\"verified\"])==\"True\":\n",
    "            x, y, w, h = coordinatesOfGroupPhoto[\"x\"], coordinatesOfGroupPhoto[\"y\"], coordinatesOfGroupPhoto[\"w\"], coordinatesOfGroupPhoto[\"h\"]\n",
    "            cv2.rectangle(camera_photo, (x, y), (x + w, y + h), colors[k], 2)  # Color verde, grosor 2\n",
    "            padding = 5  # Espacio entre el rectángulo y el cuadro de texto\n",
    "            text_box_height = 25  # Altura del cuadro de texto\n",
    "            # Agregar texto dentro del recuadro de texto\n",
    "            cv2.putText(camera_photo, f\"{student_name}\", (left + 10, top - padding - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, colors[k], 1)\n",
    "            print(f\"{student_name} was recognized in photo {m}\")\n",
    "            recognized_counter=recognized_counter+1\n",
    "        else:\n",
    "            print(f\"{student_name} was NOT recognized in photo {m}\")\n",
    "\n",
    "        k=k+1\n",
    "\n",
    "    output_path = rf\"C:\\Users\\User\\Desktop\\FinalProject\\ImagesDeepface\\Recognition\\Recognition{model}\\faces_in_classroom{m}_{recognized_counter}.jpg\"\n",
    "        # Guardar la imagen modificada\n",
    "    cv2.imwrite(output_path, camera_photo)\n",
    "    print(f\"Imagen guardada en: {output_path}\")\n",
    "    m=m+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematical metrics for analizing facial similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity is 0.35477153678865364\n",
      "Euclidean distance is 3.8419692767006404\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import euclidean,cosine\n",
    "\n",
    "#Obtain the analysis of the image\n",
    "embedding1=DeepFace.represent(img_path=\"single2.jpeg\",model_name=\"ArcFace\", detector_backend=\"retinaface\")\n",
    "embedding2=DeepFace.represent(img_path=\"single11.jpeg\",model_name=\"ArcFace\", detector_backend=\"retinaface\")\n",
    "\n",
    "#Extract the multi-dimensional vector only\n",
    "embedding1Vector1=np.array(embedding1[0][\"embedding\"])\n",
    "embedding1Vector2=embedding2[0][\"embedding\"]\n",
    "\n",
    "def cosine_similarity(embedding1, embedding2):\n",
    "    dot_product = np.dot(embedding1, embedding2)\n",
    "    norm1 = np.linalg.norm(embedding1)\n",
    "    norm2 = np.linalg.norm(embedding2)\n",
    "    similarity = dot_product / (norm1 * norm2)\n",
    "    return similarity\n",
    "\n",
    "print(\"Cosine similarity is \"+ str(cosine_similarity(embedding1Vector1,embedding1Vector2)))\n",
    "\n",
    "def euclidean_distance(embedding1,embedding2):\n",
    "    return euclidean(embedding1,embedding2)\n",
    "\n",
    "print(\"Euclidean distance is \"+ str(euclidean_distance(embedding1Vector1,embedding1Vector2)))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
