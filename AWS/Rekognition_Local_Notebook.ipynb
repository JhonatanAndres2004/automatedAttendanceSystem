{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv \n",
    "import cv2\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get environment variables and create AWS Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dotenv_path = os.path.join(\"..\",'.env')\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "#Connect to AWS Ressource, Credentials are optionals as we are accessing from the same AWS user\n",
    "client=boto3.client('rekognition',aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "    aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "    region_name=os.getenv(\"REGION_NAME\"))\n",
    "\n",
    "\n",
    "#Define bucket name to access\n",
    "\n",
    "#Folder of real classroom photos\n",
    "classroomFolder=os.path.join(\"..\",\"ImagesRekognition\",\"RealClassroomPhotos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take all images of the folder and for each draw detected faces and save it to FacesDetectedInClassroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Cycle that only draws rectangles where there are faces according to Rekognition's algorithm\n",
    "i=1\n",
    "boundingBoxDetectedFaces=[]\n",
    "\n",
    "for file in os.listdir(classroomFolder):\n",
    "    camera_local_file = os.path.join(\"..\",\"ImagesRekognition\",\"RealClassroomPhotos\",file)\n",
    "    #convert files to bytes in order to be able to read it\n",
    "\n",
    "    with open(camera_local_file, 'rb') as image_file:\n",
    "        camera_file_bytes = image_file.read()\n",
    "    responseDetection=client.detect_faces( Image={'Bytes': camera_file_bytes})\n",
    "    # Read the image with OpenCV\n",
    "    image = cv2.imread(camera_local_file)\n",
    "    image_height, image_width, _ = image.shape\n",
    "\n",
    "    boundingBoxDetectedFacesithImage=[]\n",
    "\n",
    "    # Draw bounding boxes for each detected face\n",
    "    for face in responseDetection['FaceDetails']:\n",
    "        bbox = face['BoundingBox']\n",
    "        left = int(bbox['Left'] * image_width)\n",
    "        top = int(bbox['Top'] * image_height)\n",
    "        width = int(bbox['Width'] * image_width)\n",
    "        height = int(bbox['Height'] * image_height)\n",
    "        cv2.rectangle(\n",
    "            image, \n",
    "            (left, top), \n",
    "            (left + width, top + height), \n",
    "            (37, 173, 250), \n",
    "            2  \n",
    "        )\n",
    "        boundingBoxDetectedFacesithImage.append((left, top, width,height))\n",
    "    #Each array element represents a sub-array of tuples containing the bonding boxes    \n",
    "    boundingBoxDetectedFaces.append(boundingBoxDetectedFacesithImage) \n",
    "    # Print number of faces detected\n",
    "    print(f\"{len(responseDetection['FaceDetails'])} Faces were detected\")\n",
    "\n",
    "    # Save the annotated image\n",
    "    output_path =os.path.join(\"..\",\"ImagesRekognition\",\"FacesDetectedInClassroom\",f\"faces_detected_{i}.jpeg\")\n",
    "    cv2.imwrite(output_path, image)\n",
    "    #Increase the photo's index\n",
    "    i=i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(classroomFolder):\n",
    "    if (int(str(file).split(\".\")[0][-1])>3):\n",
    "        print(str(file).split(\".\")[0][-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_iou_detection(box1, box2):\n",
    "    \"\"\"\n",
    "    Calculate IoU between 2 boxes.\n",
    "    box1, box2: tuples like (x, y, width, height)\n",
    "    return IoU value that ranges from 0 to 1\n",
    "    \"\"\"\n",
    "    x1, y1, w1, h1 = box1\n",
    "    x2, y2, w2, h2 = box2\n",
    "    \n",
    "    x_intersect_1 = max(x1, x2)\n",
    "    y_intersect_1 = max(y1, y2)\n",
    "    x_intersect_2 = min(x1 + w1, x2 + w2)\n",
    "    y_intersect_2 = min(y1 + h1, y2 + h2)\n",
    "    \n",
    "    if x_intersect_2 <= x_intersect_1 or y_intersect_2 <= y_intersect_1:\n",
    "        return 0.0\n",
    "    \n",
    "    area_intersect = (x_intersect_2 - x_intersect_1) * (y_intersect_2 - y_intersect_1)\n",
    "    area_box1 = w1 * h1\n",
    "    area_box2 = w2 * h2\n",
    "    \n",
    "    area_union = area_box1 + area_box2 - area_intersect\n",
    "    \n",
    "    iou = area_intersect / area_union\n",
    "    \n",
    "    return iou\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "true=True\n",
    "\n",
    "\n",
    "with open(os.path.join(\"..\",\"Data\",\"groundTruth.txt\"), \"r\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "\n",
    "groundTruth=ast.literal_eval(content)\n",
    "\n",
    "m=1\n",
    "#The N-Element contains tuples of the N-Th image with informations of students to be recognized\n",
    "tuples=[]\n",
    "for element in groundTruth:\n",
    "    i=1\n",
    "    #(f\"photo {m}-----------------------------------------\")\n",
    "    filteredgroundTruthObject=element[next(iter(element))][\"regions\"]\n",
    "    tuplesnthPhoto=[]\n",
    "    for element in filteredgroundTruthObject:\n",
    "        #print(f\"Person {i}-----\")\n",
    "        region=element[\"shape_attributes\"]\n",
    "        tuplesnthPhoto.append((region[\"x\"],region[\"y\"], region[\"width\"], region[\"height\"]))\n",
    "        i=i+1\n",
    "    tuples.append(tuplesnthPhoto)\n",
    "    m=m+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "TPTotal=0\n",
    "TNTotal=0\n",
    "FPTotal=0\n",
    "FNTotal=0\n",
    "\n",
    "for element in tuples:\n",
    "    TP=0\n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP=0\n",
    "    verifiedPredictions=0    \n",
    "    print(f\"------Results for image {i+1}------\")\n",
    "    for face in element: #Compare each face of ground truth with the predictions' array. If found, add TP, if not identified, add FN\n",
    "        found=False\n",
    "        for detectedFace in boundingBoxDetectedFaces[i]:\n",
    "            IoU=calculate_iou_detection(face, detectedFace)\n",
    "            if (IoU>=0.5):\n",
    "                found=True\n",
    "                TP=TP+1\n",
    "                verifiedPredictions=verifiedPredictions+1\n",
    "                break\n",
    "        if (found==False):\n",
    "            FN=FN+1\n",
    "    FP=FP+(len(boundingBoxDetectedFaces[i])-verifiedPredictions)\n",
    "    print(F\"TP: {TP}, TN:{TN}, FP:{FP} FN:{FN}\")\n",
    "    TPTotal=TPTotal+TP\n",
    "    TNTotal=TNTotal+TN\n",
    "    FPTotal=FPTotal+FP\n",
    "    FNTotal=FNTotal+FN\n",
    "\n",
    "\n",
    "    i=i+1\n",
    "\n",
    "\n",
    "print(\"----Total----\")\n",
    "print(f\"TP: {TPTotal}, TN: {TNTotal}, FP:{FPTotal},FN: {FNTotal}\")      \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take all images of the folder and all student's personal image and draw a unique color rectangle if recognized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\n",
    "    (255, 0, 0),     \n",
    "    (0, 255, 0),     \n",
    "    (0, 0, 255),     \n",
    "    (255, 255, 0),   \n",
    "    (255, 0, 255),   \n",
    "    (0, 255, 255),  \n",
    "    (128, 0, 0),     \n",
    "    (0, 128, 0),     \n",
    "    (0, 0, 128),      \n",
    "    (128, 128, 0),    \n",
    "    (128, 0, 128),    \n",
    "    (0, 128, 128),    \n",
    "    (64, 0, 128),     \n",
    "    (128, 128, 255),  \n",
    "    (0, 255, 128),   \n",
    "    (128, 255, 128),  \n",
    "    (192, 64, 64),   \n",
    "    (64, 192, 192),  \n",
    "    (255, 128, 192), \n",
    "    (32, 64, 255)    \n",
    "]\n",
    "#Array that contains all faces recognized in all test images. Each photo corresponds to the n-th array element\n",
    "boundingBoxRecognizedFaces=[]\n",
    "recognized_counter_array=[]\n",
    "m=1\n",
    "photo_index=1\n",
    "\n",
    "#Create image of the class with all faces recognized in it\n",
    "for file in os.listdir(classroomFolder):\n",
    "    camera_local_file = os.path.join(\"..\",\"ImagesRekognition\",\"RealClassroomPhotos\", file)\n",
    "    print(f\"Using index {photo_index}\")\n",
    "\n",
    "    if (photo_index>=1 and photo_index<=2) or  (photo_index>=23 and photo_index<=30):\n",
    "        selectedCourse=\"StudentsRobotics\"\n",
    "        student_array=[\"AlbaQuiroz\", \"AlejandroCasallas\",\"AlejandroVelasco\",\"AlexanderDominguez\",\"AndresAnillo\",\"CarlosBornacelly\",\"DavidChaparro\"\n",
    "                    ,\"EstebanToro\",\"GabrielCastanez\",\"GiohanOlivares\",\"JesusCotes\",\"JoseVilla\",\"JuanMolina\" ,\"ManuelRangel\",\"MariaBerdugo\",\"MariaLopez\",\n",
    "                    \"MauricioDeLaHoz\", \"SergioFonseca\",\"YordiRochel\"]    \n",
    "    elif (photo_index>=3 and photo_index<=5) or (photo_index>=8 and photo_index<=14):\n",
    "        selectedCourse=\"StudentsElectronicDesign1\"\n",
    "        student_array=[\"AllysonSalom\", \"AngieValencia\",\"DanielDelgado\",\"DiegoGomez\", \"DylanDeOro\",\"FelipeOspino\",\"HabidAbdala\",\"JuanLozano\",\"WilmanDaza\"]\n",
    "\n",
    "    elif (photo_index>=6 and photo_index<=7) or  (photo_index>=15 and photo_index<=22):\n",
    "        selectedCourse=\"StudentsElectronicDesign2\"\n",
    "        student_array=[\"AliRada\",\"AndreaQuintero\",\"AndresFabregas\",\"AndresNarvaez\",\"BrayanRubiano\",\"DiegoGomez\",\"EdwinUtria\",\"GabrielaBecerra\",\n",
    "                    \"JuanHernandez\",\"JuanQuintero\",\"JuanSanchez\",\"LucianaDeLaRosa\",\"MariaFerrer\",\"MayraCarreno\",\n",
    "                    \"OctavioMorales\",\"SamirBarcelo\",\"SteevenBallena\"]\n",
    "\n",
    "    #convert files to bytes in order to be able to read it\n",
    "    with open(camera_local_file, 'rb') as image_file:\n",
    "        camera_file_bytes = image_file.read()\n",
    "    responseDetection=client.detect_faces( Image={'Bytes': camera_file_bytes})\n",
    "    image = cv2.imread(camera_local_file)\n",
    "\n",
    "    k=0\n",
    "    recognized_counter=0\n",
    "\n",
    "    boundingBoxRecognizedFacesithImage=[]\n",
    "\n",
    "    for student_name in student_array:\n",
    "        student_found = False  # Flag to check if the student was found\n",
    "        \n",
    "        student_id_photo=os.path.join(\"..\",\"ImagesRekognition\",selectedCourse, f\"{student_name}.jpg\")\n",
    "        if not os.path.exists(student_id_photo):\n",
    "            student_id_photo=os.path.join(\"..\",\"ImagesRekognition\",selectedCourse, f\"{student_name}.jpeg\")\n",
    "            \n",
    "        with open(student_id_photo, 'rb') as image_file:\n",
    "            student_id_photo_bytes = image_file.read()\n",
    "\n",
    "        #Look for the face in SourceImage evaluating all the faces in TargetImage\n",
    "        responseRecognition=client.compare_faces(\n",
    "            SourceImage={'Bytes': student_id_photo_bytes},\n",
    "            TargetImage={'Bytes': camera_file_bytes},\n",
    "            SimilarityThreshold=50\n",
    "        )\n",
    "        # Read the target image with OpenCV\n",
    "\n",
    "        # Get image dimensions\n",
    "        image_height, image_width, _ = image.shape\n",
    "\n",
    "        # Draw bounding boxes for matched faces\n",
    "        for faceMatch in responseRecognition['FaceMatches']:\n",
    "            # Get bounding box coordinates\n",
    "            bbox = faceMatch['Face']['BoundingBox']\n",
    "            \n",
    "            # Convert normalized coordinates to pixel coordinates\n",
    "            left = int(bbox['Left'] * image_width)\n",
    "            top = int(bbox['Top'] * image_height)\n",
    "            width = int(bbox['Width'] * image_width)\n",
    "            height = int(bbox['Height'] * image_height)\n",
    "        \n",
    "            # Draw green rectangle (to differentiate from previous red detection boxes)\n",
    "            cv2.rectangle(\n",
    "                image, \n",
    "                (left, top), \n",
    "                (left + width, top + height), \n",
    "                colors[k],  # Green color in BGR\n",
    "                2,\n",
    "            )\n",
    "            \n",
    "            padding = 5  # Espacio entre el rectÃ¡ngulo y el cuadro de texto\n",
    "            text_box_height = 25  # Altura del cuadro de texto\n",
    "            # Agregar texto dentro del recuadro de texto\n",
    "            cv2.putText(image, f\"{student_name}\", (left + 10, top - padding - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, colors[k], 1)\n",
    "\n",
    "            recognized_counter=recognized_counter+1\n",
    "            print('Face at coordinates ' + str(bbox) + ' matches with ' + str(faceMatch['Similarity']) + '% confidence'+ f\"and is likely {student_name}\")\n",
    "\n",
    "            #Save the identity and region as a tuple in the n-th array element that corresponds to the n-th image\n",
    "            boundingBoxRecognizedFacesithImage.append((student_name,left,top,width,height))\n",
    "            student_found = True \n",
    "        \n",
    "        if not student_found:\n",
    "            boundingBoxRecognizedFacesithImage.append((student_name, 0, 0, 0, 0))\n",
    "            print(f\"Student {student_name} not found in the image\")\n",
    "            \n",
    "        k=k-1\n",
    "    boundingBoxRecognizedFaces.append(boundingBoxRecognizedFacesithImage)\n",
    "    recognized_counter_array.append(recognized_counter)\n",
    "    # Save the annotated image\n",
    "    output_path = os.path.join(\"..\",\"ImagesRekognition\",\"StudentsFoundInClassroom95\", f\"faces_in_classroom_{m}_{recognized_counter}.jpeg\")\n",
    "    cv2.imwrite(output_path, image)\n",
    "    print(f\"Annotated image saved to {output_path}\")\n",
    "    m=m+1\n",
    "    photo_index=photo_index+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain tuples from base line (Manual correction and verification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(os.path.join(\"..\",\"Data\",\"faceGallery.txt\"), \"r\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "faceGallery=ast.literal_eval(content)\n",
    "\n",
    "\n",
    "m=1\n",
    "#The N-Element contains tuples of the N-Th image with informations of students to be recognized\n",
    "tuples=[]\n",
    "for element in faceGallery:\n",
    "    i=1\n",
    "    #(f\"photo {m}-----------------------------------------\")\n",
    "    filteredFaceGalleryObject=element[next(iter(element))][\"regions\"]\n",
    "    tuplesnthPhoto=[]\n",
    "    for element in filteredFaceGalleryObject:\n",
    "        #print(f\"Person {i}-----\")\n",
    "        region=element[\"shape_attributes\"]\n",
    "        identity=element[\"region_attributes\"]\n",
    "        #print(f\"x = {region[\"x\"]} \\ny = {region[\"y\"]} \\nwidth = {region[\"width\"]}\\nheight = {region[\"height\"]} \\nidentifier = {identity[\"name\"]}\")\n",
    "        tuplesnthPhoto.append((identity[\"name\"],region[\"x\"],region[\"y\"], region[\"width\"], region[\"height\"]))\n",
    "        i=i+1\n",
    "    tuples.append(tuplesnthPhoto)\n",
    "    m=m+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to calculate IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"\n",
    "    Calculate IoU between 2 boxes.\n",
    "    box1, box2: tuples like (x, y, width, height)\n",
    "    return IoU value that ranges from 0 to 1\n",
    "    \"\"\"\n",
    "    name1,x1, y1, w1, h1 = box1\n",
    "    name2, x2, y2, w2, h2 = box2\n",
    "    \n",
    "    x_intersect_1 = max(x1, x2)\n",
    "    y_intersect_1 = max(y1, y2)\n",
    "    x_intersect_2 = min(x1 + w1, x2 + w2)\n",
    "    y_intersect_2 = min(y1 + h1, y2 + h2)\n",
    "    \n",
    "    if x_intersect_2 <= x_intersect_1 or y_intersect_2 <= y_intersect_1:\n",
    "        return 0.0\n",
    "    \n",
    "    area_intersect = (x_intersect_2 - x_intersect_1) * (y_intersect_2 - y_intersect_1)\n",
    "    area_box1 = w1 * h1\n",
    "    area_box2 = w2 * h2\n",
    "    \n",
    "    area_union = area_box1 + area_box2 - area_intersect\n",
    "    \n",
    "    iou = area_intersect / area_union\n",
    "    \n",
    "    return iou\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate through the base line and compare it to the results obtained by Rekognition. Then calculate TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for photo 1\n",
      "TP : 17 \n",
      "TN : 360 \n",
      "FP : 0 \n",
      "FN : 1 \n",
      " F1: 0.9714285714285714\n",
      "Results for photo 2\n",
      "conflict between AlexanderDominguez and ManuelRangel in element ('AlexanderDominguez', 617, 336, 20, 25)\n",
      "TP : 16 \n",
      "TN : 358 \n",
      "FP : 1 \n",
      "FN : 3 \n",
      " F1: 0.8888888888888888\n",
      "Results for photo 3\n",
      "TP : 7 \n",
      "TN : 56 \n",
      "FP : 0 \n",
      "FN : 0 \n",
      " F1: 1.0\n",
      "Results for photo 4\n",
      "TP : 7 \n",
      "TN : 56 \n",
      "FP : 0 \n",
      "FN : 0 \n",
      " F1: 1.0\n",
      "Results for photo 5\n",
      "TP : 7 \n",
      "TN : 56 \n",
      "FP : 0 \n",
      "FN : 0 \n",
      " F1: 1.0\n",
      "Results for photo 6\n",
      "TP : 16 \n",
      "TN : 289 \n",
      "FP : 0 \n",
      "FN : 1 \n",
      " F1: 0.9696969696969697\n",
      "Results for photo 7\n",
      "TP : 16 \n",
      "TN : 306 \n",
      "FP : 0 \n",
      "FN : 1 \n",
      " F1: 0.9696969696969697\n",
      "Results for photo 8\n",
      "TP : 8 \n",
      "TN : 64 \n",
      "FP : 0 \n",
      "FN : 0 \n",
      " F1: 1.0\n",
      "Results for photo 9\n",
      "TP : 6 \n",
      "TN : 56 \n",
      "FP : 0 \n",
      "FN : 1 \n",
      " F1: 0.923076923076923\n",
      "Results for photo 10\n",
      "TP : 7 \n",
      "TN : 64 \n",
      "FP : 0 \n",
      "FN : 1 \n",
      " F1: 0.9333333333333333\n",
      "Results for photo 11\n",
      "TP : 8 \n",
      "TN : 64 \n",
      "FP : 0 \n",
      "FN : 0 \n",
      " F1: 1.0\n",
      "Results for photo 12\n",
      "TP : 7 \n",
      "TN : 56 \n",
      "FP : 0 \n",
      "FN : 0 \n",
      " F1: 1.0\n",
      "Results for photo 13\n",
      "TP : 7 \n",
      "TN : 56 \n",
      "FP : 0 \n",
      "FN : 0 \n",
      " F1: 1.0\n",
      "Results for photo 14\n",
      "TP : 5 \n",
      "TN : 56 \n",
      "FP : 0 \n",
      "FN : 2 \n",
      " F1: 0.8333333333333333\n",
      "Results for photo 15\n",
      "TP : 8 \n",
      "TN : 170 \n",
      "FP : 0 \n",
      "FN : 2 \n",
      " F1: 0.888888888888889\n",
      "Results for photo 16\n",
      "TP : 7 \n",
      "TN : 150 \n",
      "FP : 0 \n",
      "FN : 3 \n",
      " F1: 0.8235294117647058\n",
      "Results for photo 17\n",
      "TP : 6 \n",
      "TN : 96 \n",
      "FP : 0 \n",
      "FN : 0 \n",
      " F1: 1.0\n",
      "Results for photo 18\n",
      "TP : 6 \n",
      "TN : 128 \n",
      "FP : 0 \n",
      "FN : 2 \n",
      " F1: 0.8571428571428571\n",
      "Results for photo 19\n",
      "TP : 5 \n",
      "TN : 98 \n",
      "FP : 0 \n",
      "FN : 2 \n",
      " F1: 0.8333333333333333\n",
      "Results for photo 20\n",
      "TP : 6 \n",
      "TN : 128 \n",
      "FP : 0 \n",
      "FN : 2 \n",
      " F1: 0.8571428571428571\n",
      "Results for photo 21\n",
      "TP : 10 \n",
      "TN : 208 \n",
      "FP : 0 \n",
      "FN : 3 \n",
      " F1: 0.8695652173913044\n",
      "Results for photo 22\n",
      "TP : 7 \n",
      "TN : 160 \n",
      "FP : 0 \n",
      "FN : 3 \n",
      " F1: 0.8235294117647058\n",
      "Results for photo 23\n",
      "TP : 8 \n",
      "TN : 135 \n",
      "FP : 0 \n",
      "FN : 1 \n",
      " F1: 0.9411764705882353\n",
      "Results for photo 24\n",
      "TP : 11 \n",
      "TN : 234 \n",
      "FP : 0 \n",
      "FN : 2 \n",
      " F1: 0.9166666666666666\n",
      "Results for photo 25\n",
      "TP : 11 \n",
      "TN : 221 \n",
      "FP : 0 \n",
      "FN : 2 \n",
      " F1: 0.9166666666666666\n",
      "Results for photo 26\n",
      "TP : 14 \n",
      "TN : 196 \n",
      "FP : 0 \n",
      "FN : 0 \n",
      " F1: 1.0\n",
      "Results for photo 27\n",
      "TP : 13 \n",
      "TN : 208 \n",
      "FP : 0 \n",
      "FN : 0 \n",
      " F1: 1.0\n",
      "Results for photo 28\n",
      "TP : 11 \n",
      "TN : 192 \n",
      "FP : 0 \n",
      "FN : 1 \n",
      " F1: 0.9565217391304348\n",
      "Results for photo 29\n",
      "TP : 10 \n",
      "TN : 154 \n",
      "FP : 0 \n",
      "FN : 1 \n",
      " F1: 0.9523809523809523\n",
      "Results for photo 30\n",
      "TP : 7 \n",
      "TN : 136 \n",
      "FP : 0 \n",
      "FN : 1 \n",
      " F1: 0.9333333333333333\n",
      "----Total----\n",
      "TP: 274, TN: 4511, FP:1,FN: 35\n",
      "[0.9714285714285714, 0.8888888888888888, 1.0, 1.0, 1.0, 0.9696969696969697, 0.9696969696969697, 1.0, 0.923076923076923, 0.9333333333333333, 1.0, 1.0, 1.0, 0.8333333333333333, 0.888888888888889, 0.8235294117647058, 1.0, 0.8571428571428571, 0.8333333333333333, 0.8571428571428571, 0.8695652173913044, 0.8235294117647058, 0.9411764705882353, 0.9166666666666666, 0.9166666666666666, 1.0, 1.0, 0.9565217391304348, 0.9523809523809523, 0.9333333333333333]\n"
     ]
    }
   ],
   "source": [
    "#It searchs based on face gallery/Base Line: It compares my definition of the existance of specific students and compares it to the found studens\n",
    "#The result wouldn't be affected if the search direction is reversed\n",
    "\n",
    "i=0\n",
    "TPTotal=0\n",
    "TNTotal=0\n",
    "FPTotal=0\n",
    "FNTotal=0\n",
    "F1ARRAY=[]\n",
    "#Loop through all the photos\n",
    "for photoObject in tuples:\n",
    "    print(f\"Results for photo {i+1}\")\n",
    "    TP=0\n",
    "    TN=0\n",
    "    FP=0\n",
    "    FN=0\n",
    "    #Obtain the array of faces recognized with Rekognition in that photo\n",
    "    tuplesToCompare=boundingBoxRecognizedFaces[i]\n",
    "\n",
    "    listOfNamesBaseline=[]\n",
    "    for element in photoObject:\n",
    "        listOfNamesBaseline.append(element[0])\n",
    "\n",
    "    listOfNamesModel=[]\n",
    "    for element in tuplesToCompare:\n",
    "        listOfNamesModel.append(element[0])\n",
    "\n",
    "\n",
    "    for element in photoObject:\n",
    "        if(element[0] in listOfNamesModel):\n",
    "            for identity in tuplesToCompare:\n",
    "                IoU=calculate_iou(element,identity)\n",
    "\n",
    "                #Case True Positive: Identity and bounding box match\n",
    "                if(IoU>=0.5 and element[0]==identity[0]):\n",
    "                    TP=TP+1\n",
    "\n",
    "                #Case False Positive: no identity match, however, the bounding boxes are similar\n",
    "                if(IoU>=0.5 and element[0]!=identity[0]):\n",
    "                    FP=FP+1\n",
    "                    print(f\"conflict between {element[0]} and {identity[0]} in element {element}\")\n",
    "\n",
    "                #Case True Negative: No bounding box match. However, the identity is different\n",
    "                if(IoU<0.5 and element[0]!=identity[0]):\n",
    "                    TN=TN+1\n",
    "                #Case False Negative: The identity matches. However, bonding boxes do not correspond\n",
    "                if(IoU<0.5 and element[0]==identity[0]):\n",
    "                    FN=FN+1 \n",
    "            \n",
    "            #Correction to take into account if the model doesn't mistake identities of strangers: Detected Faces-Faces identified        \n",
    "            TN=TN+len(boundingBoxDetectedFaces[i])-len(listOfNamesModel)\n",
    "        else:\n",
    "            FN=FN+1\n",
    "            TN=TN+len(boundingBoxDetectedFaces[i])-1\n",
    "            print(f\"{element[0]} not in model's list and adds 1 FN and {len(boundingBoxDetectedFaces)-1} TN\")\n",
    "            \n",
    "    TPTotal=TPTotal+TP\n",
    "    TNTotal=TNTotal+TN\n",
    "    FPTotal=FPTotal+FP\n",
    "    FNTotal=FNTotal+FN\n",
    "    SNS=TP/(TP+FN)\n",
    "    PRC=TP/(TP+FP)\n",
    "    F1ELEMENT=2*SNS*PRC/(SNS+PRC)\n",
    "    F1ARRAY.append(F1ELEMENT)\n",
    "    #print(recognized_counter_array[i])\n",
    "    print(f\"TP : {TP} \\nTN : {TN} \\nFP : {FP} \\nFN : {FN} \\n F1: {F1ELEMENT}\")\n",
    "    i=i+1\n",
    "\n",
    "print(\"----Total----\")\n",
    "print(f\"TP: {TPTotal}, TN: {TNTotal}, FP:{FPTotal},FN: {FNTotal}\") \n",
    "\n",
    "print(F1ARRAY)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
