{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv \n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get environment variables and create AWS Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dotenv_path = os.path.join(\"..\", 'interface', '.env')\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "#Connect to AWS Ressource, Credentials are optionals as we are accessing from the same AWS user\n",
    "client=boto3.client('rekognition',aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "    aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "    region_name=os.getenv(\"REGION_NAME\"))\n",
    "s3 = boto3.client('s3',\n",
    "    aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "    aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "    region_name=os.getenv(\"REGION_NAME\")\n",
    ")\n",
    "\n",
    "#Define bucket name to access\n",
    "bucket_name = os.getenv(\"BUCKET_NAME\")\n",
    "\n",
    "#Folder of real classroom photos\n",
    "classroomFolder=r\"C:\\Users\\User\\Desktop\\FinalProject\\ImagesRekognition\\RealClassroomPhotos\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take all images of the folder and for each draw detected faces and save it to FacesDetectedInClassroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 Faces were detected\n",
      "15 Faces were detected\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Cycle that only draws rectangles where there are faces according to Rekognition's algorithm\n",
    "i=1\n",
    "boundingBoxDetectedFaces=[]\n",
    "\n",
    "for file in os.listdir(classroomFolder):\n",
    "    camera_local_file = rf'C:\\Users\\User\\Desktop\\FinalProject\\ImagesRekognition\\RealClassroomPhotos\\{file}' \n",
    "    #convert files to bytes in order to be able to read it\n",
    "\n",
    "    with open(camera_local_file, 'rb') as image_file:\n",
    "        camera_file_bytes = image_file.read()\n",
    "    responseDetection=client.detect_faces( Image={'Bytes': camera_file_bytes})\n",
    "    \n",
    "    # Read the image with OpenCV\n",
    "    image = cv2.imread(camera_local_file)\n",
    "    image_height, image_width, _ = image.shape\n",
    "\n",
    "    boundingBoxDetectedFacesithImage=[]\n",
    "\n",
    "    # Draw bounding boxes for each detected face\n",
    "    for face in responseDetection['FaceDetails']:\n",
    "        bbox = face['BoundingBox']\n",
    "        left = int(bbox['Left'] * image_width)\n",
    "        top = int(bbox['Top'] * image_height)\n",
    "        width = int(bbox['Width'] * image_width)\n",
    "        height = int(bbox['Height'] * image_height)\n",
    "        cv2.rectangle(\n",
    "            image, \n",
    "            (left, top), \n",
    "            (left + width, top + height), \n",
    "            (37, 173, 250), \n",
    "            2  \n",
    "        )\n",
    "        boundingBoxDetectedFacesithImage.append((left, top, width,height))\n",
    "    #Each array element represents a sub-array of tuples containing the bonding boxes    \n",
    "    boundingBoxDetectedFaces.append(boundingBoxDetectedFacesithImage) \n",
    "    # Print number of faces detected\n",
    "    print(f\"{len(responseDetection['FaceDetails'])} Faces were detected\")\n",
    "\n",
    "    # Save the annotated image\n",
    "    output_path = rf\"C:\\Users\\User\\Desktop\\FinalProject\\ImagesRekognition\\FacesDetectedInClassroom\\faces_detected_{i}.jpeg\"\n",
    "    cv2.imwrite(output_path, image)\n",
    "    #Increase the photo's index\n",
    "    i=i+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take all images of the folder and all student's personal image and draw a unique color rectangle if recognized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face at coordinates {'Width': 0.02335977554321289, 'Height': 0.039030011743307114, 'Left': 0.5729531049728394, 'Top': 0.41381317377090454} matches with 99.63961029052734% confidenceand is likely AlejandroCallasas\n",
      "Face at coordinates {'Width': 0.026119183748960495, 'Height': 0.039969634264707565, 'Left': 0.1270674467086792, 'Top': 0.50046706199646} matches with 93.06892395019531% confidenceand is likely AndresAnillo\n",
      "Student DiegoGomez not found in the image\n",
      "Face at coordinates {'Width': 0.025718938559293747, 'Height': 0.04472402110695839, 'Left': 0.013418024405837059, 'Top': 0.5241779088973999} matches with 89.78019714355469% confidenceand is likely GabrielCastanez\n",
      "Face at coordinates {'Width': 0.017744731158018112, 'Height': 0.02946370467543602, 'Left': 0.5593912601470947, 'Top': 0.36348745226860046} matches with 86.79216766357422% confidenceand is likely MauricioDeLaHoz\n",
      "Face at coordinates {'Width': 0.02150445058941841, 'Height': 0.035746827721595764, 'Left': 0.2898186147212982, 'Top': 0.4404120445251465} matches with 98.82011413574219% confidenceand is likely YordiRochel\n",
      "Face at coordinates {'Width': 0.022375106811523438, 'Height': 0.03927338868379593, 'Left': 0.9031990766525269, 'Top': 0.37748441100120544} matches with 91.80164337158203% confidenceand is likely MariaBerdugo\n",
      "Face at coordinates {'Width': 0.01915607415139675, 'Height': 0.03156420215964317, 'Left': 0.7100282907485962, 'Top': 0.36011409759521484} matches with 87.82648468017578% confidenceand is likely AlbaQuiroz\n",
      "Face at coordinates {'Width': 0.02227344550192356, 'Height': 0.036465007811784744, 'Left': 0.9298283457756042, 'Top': 0.3401082158088684} matches with 98.22644805908203% confidenceand is likely GiohanOlivares\n",
      "Face at coordinates {'Width': 0.031433843076229095, 'Height': 0.058577727526426315, 'Left': 0.09286067634820938, 'Top': 0.5581098198890686} matches with 99.77782440185547% confidenceand is likely JesusCotes\n",
      "Annotated image saved to C:\\Users\\User\\Desktop\\FinalProject\\ImagesRekognition\\StudentFoundInClassroom\\faces_in_classroom_1_9.jpeg\n",
      "Student AlejandroCallasas not found in the image\n",
      "Face at coordinates {'Width': 0.0254167802631855, 'Height': 0.039310965687036514, 'Left': 0.1266854703426361, 'Top': 0.5067814588546753} matches with 96.13477325439453% confidenceand is likely AndresAnillo\n",
      "Student DiegoGomez not found in the image\n",
      "Student GabrielCastanez not found in the image\n",
      "Student MauricioDeLaHoz not found in the image\n",
      "Face at coordinates {'Width': 0.023255253210663795, 'Height': 0.036906879395246506, 'Left': 0.324034720659256, 'Top': 0.4467530846595764} matches with 95.25985717773438% confidenceand is likely YordiRochel\n",
      "Student MariaBerdugo not found in the image\n",
      "Student AlbaQuiroz not found in the image\n",
      "Student GiohanOlivares not found in the image\n",
      "Student JesusCotes not found in the image\n",
      "Annotated image saved to C:\\Users\\User\\Desktop\\FinalProject\\ImagesRekognition\\StudentFoundInClassroom\\faces_in_classroom_2_2.jpeg\n"
     ]
    }
   ],
   "source": [
    "student_array=[\"AlejandroCallasas\", \"AndresAnillo\",\"DiegoGomez\",\"GabrielCastanez\", \"MauricioDeLaHoz\",\"YordiRochel\", \"MariaBerdugo\",\"AlbaQuiroz\",\"GiohanOlivares\",\"JesusCotes\"]\n",
    "numberOfStudents=len(student_array)\n",
    "colors=[(0, 200, 0),(200,0,0),(0,0,0), (0,0,255), (150,150,0),(0,150,150),(100,20,60),(20,60,100),(60,100,20),(255,255,255)]\n",
    "\n",
    "#Array that contains all faces recognized in all test images. Each photo corresponds to the n-th array element\n",
    "boundingBoxRecognizedFaces=[]\n",
    "\n",
    "m=1\n",
    "#Create image of the class with all faces recognized in it\n",
    "for file in os.listdir(classroomFolder):\n",
    "    camera_local_file = rf'C:\\Users\\User\\Desktop\\FinalProject\\ImagesRekognition\\RealClassroomPhotos\\{file}' \n",
    "\n",
    "    #convert files to bytes in order to be able to read it\n",
    "    with open(camera_local_file, 'rb') as image_file:\n",
    "        camera_file_bytes = image_file.read()\n",
    "    responseDetection=client.detect_faces( Image={'Bytes': camera_file_bytes})\n",
    "    image = cv2.imread(camera_local_file)\n",
    "\n",
    "    k=0\n",
    "    recognized_counter=0\n",
    "\n",
    "    boundingBoxRecognizedFacesithImage=[]\n",
    "\n",
    "    for student_name in student_array:\n",
    "        student_found = False  # Bandera para controlar si el estudiante fue encontrado\n",
    "        \n",
    "        student_id_photo=r\"C:\\Users\\User\\Desktop\\FinalProject\\ImagesRekognition\\Student\"+ rf\"s\\{student_name}.jpeg\"\n",
    "        with open(student_id_photo, 'rb') as image_file:\n",
    "            student_id_photo_bytes = image_file.read()\n",
    "\n",
    "        #Look for the face in SourceImage evaluating all the faces in TargetImage\n",
    "        responseRecognition=client.compare_faces(\n",
    "            SourceImage={'Bytes': student_id_photo_bytes},\n",
    "            TargetImage={'Bytes': camera_file_bytes},\n",
    "            SimilarityThreshold=80\n",
    "        )\n",
    "        # Read the target image with OpenCV\n",
    "\n",
    "        # Get image dimensions\n",
    "        image_height, image_width, _ = image.shape\n",
    "\n",
    "        # Draw bounding boxes for matched faces\n",
    "        for faceMatch in responseRecognition['FaceMatches']:\n",
    "            # Get bounding box coordinates\n",
    "            bbox = faceMatch['Face']['BoundingBox']\n",
    "            \n",
    "            # Convert normalized coordinates to pixel coordinates\n",
    "            left = int(bbox['Left'] * image_width)\n",
    "            top = int(bbox['Top'] * image_height)\n",
    "            width = int(bbox['Width'] * image_width)\n",
    "            height = int(bbox['Height'] * image_height)\n",
    "        \n",
    "            # Draw green rectangle (to differentiate from previous red detection boxes)\n",
    "            cv2.rectangle(\n",
    "                image, \n",
    "                (left, top), \n",
    "                (left + width, top + height), \n",
    "                colors[k],  # Green color in BGR\n",
    "                2,\n",
    "            )\n",
    "            \n",
    "            padding = 5  # Espacio entre el rectángulo y el cuadro de texto\n",
    "            text_box_height = 25  # Altura del cuadro de texto\n",
    "            # Agregar texto dentro del recuadro de texto\n",
    "            cv2.putText(image, f\"{student_name}\", (left + 10, top - padding - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, colors[k], 1)\n",
    "\n",
    "            recognized_counter=recognized_counter+1\n",
    "            print('Face at coordinates ' + str(bbox) + ' matches with ' + str(faceMatch['Similarity']) + '% confidence'+ f\"and is likely {student_name}\")\n",
    "\n",
    "            #Save the identity and region as a tuple in the n-th array element that corresponds to the n-th image\n",
    "            boundingBoxRecognizedFacesithImage.append((student_name,left,top,width,height))\n",
    "            student_found = True  # Marcamos que este estudiante fue encontrado\n",
    "        \n",
    "        # Si no se encontró al estudiante, agregar una tupla con valores cero\n",
    "        if not student_found:\n",
    "            boundingBoxRecognizedFacesithImage.append((student_name, 0, 0, 0, 0))\n",
    "            print(f\"Student {student_name} not found in the image\")\n",
    "            \n",
    "        k=k+1\n",
    "    boundingBoxRecognizedFaces.append(boundingBoxRecognizedFacesithImage)\n",
    "\n",
    "    # Save the annotated image\n",
    "    output_path = rf\"C:\\Users\\User\\Desktop\\FinalProject\\ImagesRekognition\\StudentFoundInClassroom\\faces_in_classroom_{m}_{recognized_counter}.jpeg\"\n",
    "    cv2.imwrite(output_path, image)\n",
    "    print(f\"Annotated image saved to {output_path}\")\n",
    "    m=m+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responseDetection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain tuples from base line (Manual correction and verification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "true=True\n",
    "faceGallery=[\n",
    "{\"classroom1.jpeg156424\":{\"filename\":\"classroom1.jpeg\",\"size\":156424,\"regions\":[{\"shape_attributes\":{\"name\":\"rect\",\"x\":733,\"y\":392,\"width\":31,\"height\":44},\"region_attributes\":{\"name\":\"AlejandroCallasas\",\"type\":\"unknown\",\"image_quality\":{\"good\":true,\"frontal\":true,\"good_illumination\":true}}},{\"shape_attributes\":{\"name\":\"rect\",\"x\":153,\"y\":475,\"width\":45,\"height\":46},\"region_attributes\":{\"name\":\"AndresAnillo\",\"type\":\"unknown\",\"image_quality\":{\"good\":true,\"frontal\":true,\"good_illumination\":true}}},{\"shape_attributes\":{\"name\":\"rect\",\"x\":660,\"y\":275,\"width\":20,\"height\":27},\"region_attributes\":{\"name\":\"DiegoGomez\",\"type\":\"unknown\",\"image_quality\":{\"good\":true,\"frontal\":true,\"good_illumination\":true}}},{\"shape_attributes\":{\"name\":\"rect\",\"x\":13,\"y\":506,\"width\":37,\"height\":39},\"region_attributes\":{\"name\":\"GabrielCastanez\",\"type\":\"unknown\",\"image_quality\":{\"good\":true,\"frontal\":true,\"good_illumination\":true}}},{\"shape_attributes\":{\"name\":\"rect\",\"x\":716,\"y\":348,\"width\":22,\"height\":30},\"region_attributes\":{\"name\":\"MauricioDeLaHoz\",\"type\":\"unknown\",\"image_quality\":{\"good\":true,\"frontal\":true,\"good_illumination\":true}}},{\"shape_attributes\":{\"name\":\"rect\",\"x\":367,\"y\":421,\"width\":33,\"height\":39},\"region_attributes\":{\"name\":\"YordiRochel\",\"type\":\"unknown\",\"image_quality\":{\"good\":true,\"frontal\":true,\"good_illumination\":true}}},{\"shape_attributes\":{\"name\":\"rect\",\"x\":1155,\"y\":362,\"width\":31,\"height\":35},\"region_attributes\":{\"name\":\"MariaBerdugo\",\"type\":\"unknown\",\"image_quality\":{\"good\":true,\"frontal\":true,\"good_illumination\":true}}},{\"shape_attributes\":{\"name\":\"rect\",\"x\":908,\"y\":346,\"width\":27,\"height\":31},\"region_attributes\":{\"name\":\"AlbaQuiroz\",\"type\":\"unknown\",\"image_quality\":{\"good\":true,\"frontal\":true,\"good_illumination\":true}}},{\"shape_attributes\":{\"name\":\"rect\",\"x\":1188,\"y\":326,\"width\":32,\"height\":36},\"region_attributes\":{\"name\":\"GiohanOlivares\",\"type\":\"unknown\",\"image_quality\":{\"good\":true,\"frontal\":true,\"good_illumination\":true}}},{\"shape_attributes\":{\"name\":\"rect\",\"x\":114,\"y\":534,\"width\":44,\"height\":59},\"region_attributes\":{\"name\":\"JesusCotes\",\"type\":\"unknown\",\"image_quality\":{\"good\":true,\"frontal\":true,\"good_illumination\":true}}}],\"file_attributes\":{\"caption\":\"\",\"public_domain\":\"no\",\"image_url\":\"\"}}},\n",
    "{\"classroom2.jpeg148639\":{\"filename\":\"classroom2.jpeg\",\"size\":148639,\"regions\":[{\"shape_attributes\":{\"name\":\"rect\",\"x\":147,\"y\":465,\"width\":56,\"height\":60},\"region_attributes\":{\"name\":\"AndresAnillo\",\"type\":\"unknown\",\"image_quality\":{\"good\":true,\"frontal\":true,\"good_illumination\":true}}},{\"shape_attributes\":{\"name\":\"rect\",\"x\":2,\"y\":496,\"width\":51,\"height\":64},\"region_attributes\":{\"name\":\"GabrielCastanez\",\"type\":\"unknown\",\"image_quality\":{\"good\":true,\"frontal\":true,\"good_illumination\":true}}},{\"shape_attributes\":{\"name\":\"rect\",\"x\":1206,\"y\":314,\"width\":46,\"height\":61},\"region_attributes\":{\"name\":\"GiohanOlivares\",\"type\":\"unknown\",\"image_quality\":{\"good\":true,\"frontal\":true,\"good_illumination\":true}}},{\"shape_attributes\":{\"name\":\"rect\",\"x\":154,\"y\":551,\"width\":55,\"height\":74},\"region_attributes\":{\"name\":\"GiohanOlivares\",\"type\":\"unknown\",\"image_quality\":{\"good\":true,\"frontal\":true,\"good_illumination\":true}}},{\"shape_attributes\":{\"name\":\"rect\",\"x\":1158,\"y\":347,\"width\":44,\"height\":60},\"region_attributes\":{\"name\":\"MariaBerdugo\",\"type\":\"unknown\",\"image_quality\":{\"good\":true,\"frontal\":true,\"good_illumination\":true}}},{\"shape_attributes\":{\"name\":\"rect\",\"x\":408,\"y\":415,\"width\":44,\"height\":59},\"region_attributes\":{\"name\":\"YordiRochel\",\"type\":\"unknown\",\"image_quality\":{\"good\":true,\"frontal\":true,\"good_illumination\":true}}}],\"file_attributes\":{\"caption\":\"\",\"public_domain\":\"no\",\"image_url\":\"\"}}}\n",
    "]\n",
    "\n",
    "m=1\n",
    "#The N-Element contains tuples of the N-Th image with informations of students to be recognized\n",
    "tuples=[]\n",
    "for element in faceGallery:\n",
    "    i=1\n",
    "    #(f\"photo {m}-----------------------------------------\")\n",
    "    filteredFaceGalleryObject=element[next(iter(element))][\"regions\"]\n",
    "    tuplesnthPhoto=[]\n",
    "    for element in filteredFaceGalleryObject:\n",
    "        #print(f\"Person {i}-----\")\n",
    "        region=element[\"shape_attributes\"]\n",
    "        identity=element[\"region_attributes\"]\n",
    "        #print(f\"x = {region[\"x\"]} \\ny = {region[\"y\"]} \\nwidth = {region[\"width\"]}\\nheight = {region[\"height\"]} \\nidentifier = {identity[\"name\"]}\")\n",
    "        tuplesnthPhoto.append((identity[\"name\"],region[\"x\"],region[\"y\"], region[\"width\"], region[\"height\"]))\n",
    "        i=i+1\n",
    "    tuples.append(tuplesnthPhoto)\n",
    "    m=m+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to calculate IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"\n",
    "    Calculate IoU between 2 boxes.\n",
    "    box1, box2: tuples like (x, y, width, height)\n",
    "    return IoU value that ranges from 0 to 1\n",
    "    \"\"\"\n",
    "    # Extraer coordenadas\n",
    "    name1,x1, y1, w1, h1 = box1\n",
    "    name2, x2, y2, w2, h2 = box2\n",
    "    \n",
    "    # Calcular coordenadas de la intersección\n",
    "    x_intersect_1 = max(x1, x2)\n",
    "    y_intersect_1 = max(y1, y2)\n",
    "    x_intersect_2 = min(x1 + w1, x2 + w2)\n",
    "    y_intersect_2 = min(y1 + h1, y2 + h2)\n",
    "    \n",
    "    # Comprobar si hay intersección\n",
    "    if x_intersect_2 <= x_intersect_1 or y_intersect_2 <= y_intersect_1:\n",
    "        return 0.0\n",
    "    \n",
    "    # Calcular áreas\n",
    "    area_intersect = (x_intersect_2 - x_intersect_1) * (y_intersect_2 - y_intersect_1)\n",
    "    area_box1 = w1 * h1\n",
    "    area_box2 = w2 * h2\n",
    "    \n",
    "    # Calcular unión\n",
    "    area_union = area_box1 + area_box2 - area_intersect\n",
    "    \n",
    "    # Calcular IoU\n",
    "    iou = area_intersect / area_union\n",
    "    \n",
    "    return iou\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate through the base line and compare it to the results obtained by Rekognition. Then calculate TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for photo 1\n",
      "TP : 9 \n",
      "TN : 90 \n",
      "FP : 0 \n",
      "FN : 1\n",
      "Results for photo 2\n",
      "TP : 0 \n",
      "TN : 54 \n",
      "FP : 0 \n",
      "FN : 6\n"
     ]
    }
   ],
   "source": [
    "#It searchs based on face gallery/Base Line: It compares my definition of the existance of specific students and compares it to the found studens\n",
    "#The result wouldn't be affected if the search direction is reversed\n",
    "\n",
    "i=0\n",
    "#Loop through all the photos\n",
    "for photoObject in tuples:\n",
    "    print(f\"Results for photo {i+1}\")\n",
    "    TP=0\n",
    "    TN=0\n",
    "    FP=0\n",
    "    FN=0\n",
    "    #Obtain the array of faces recognized with Rekognition in that photo\n",
    "    tuplesToCompare=boundingBoxRecognizedFaces[i]\n",
    "    #Look for every bounding box drawn in the rekognition array. Element corresponds to the drawn rectangle, identify to rekognition's precdiction\n",
    "    for element in photoObject:\n",
    "        #print(element)\n",
    "        for identity in tuplesToCompare:\n",
    "            IoU=calculate_iou(element,identity)\n",
    "            #Case True Positive: Identity and bounding box match\n",
    "            #print(f\"{element} compared with {identity}\")\n",
    "\n",
    "            if(IoU>=0.5 and element[0]==identity[0]):\n",
    "                TP=TP+1\n",
    "\n",
    "            #Case False Positive: no identity match, however, the bounding boxes are similar\n",
    "            if(IoU>=0.5 and element[0]!=identity[0]):\n",
    "                FP=FP+1\n",
    "\n",
    "            #Case True Negative: No bounding box match. However, the identity is different\n",
    "            if(IoU<0.5 and element[0]!=identity[0]):\n",
    "                TN=TN+1\n",
    "\n",
    "            #Case False Negative: The identity matches. However, bonding boxes do not correspond\n",
    "            if(IoU<0.5 and element[0]==identity[0]):\n",
    "                FN=FN+1 \n",
    "\n",
    "    print(f\"TP : {TP} \\nTN : {TN} \\nFP : {FP} \\nFN : {FN}\")\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
