{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from retinaface import RetinaFace\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from deepface import DeepFace\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Face Pattern Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define image to work with\n",
    "img_path=\"Images/real_Classroom2.jpeg\"\n",
    "img = cv2.imread(img_path)\n",
    "#Select the model to be used for detection varying the list index\n",
    "detectors = [\"opencv\", \"ssd\", \"mtcnn\", \"dlib\", \"retinaface\"]\n",
    "faces = DeepFace.extract_faces(img_path, detector_backend=detectors[4])\n",
    "facesCoordinatesList=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of detected faces : 6\n"
     ]
    }
   ],
   "source": [
    "#Extract only the coordinates features\n",
    "print(\"Number of detected faces : \" + str(len(faces)))\n",
    "for i in range(len(faces)):\n",
    "    facesCoordinatesList.append(faces[i][\"facial_area\"])\n",
    "for element in facesCoordinatesList:\n",
    "    cv2.rectangle(img, (element[\"x\"], element[\"y\"]),(element[\"x\"] + element[\"w\"], element[\"y\"] + element[\"h\"]), (73, 32, 238), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Facial recognition and metrics about position of facial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verified': True,\n",
       " 'distance': 0.06340265385761057,\n",
       " 'threshold': 0.07,\n",
       " 'model': 'Dlib',\n",
       " 'detector_backend': 'retinaface',\n",
       " 'similarity_metric': 'cosine',\n",
       " 'facial_areas': {'img1': {'x': 552,\n",
       "   'y': 189,\n",
       "   'w': 349,\n",
       "   'h': 489,\n",
       "   'left_eye': (830, 377),\n",
       "   'right_eye': (663, 399)},\n",
       "  'img2': {'x': 830,\n",
       "   'y': 537,\n",
       "   'w': 278,\n",
       "   'h': 397,\n",
       "   'left_eye': (941, 693),\n",
       "   'right_eye': (857, 699)}},\n",
       " 'time': 28.89}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objRecognition=DeepFace.verify(img1_path=\"Images/single2.jpeg\",img2_path=\"Images/single11.jpeg\",model_name=\"Dlib\",detector_backend=\"retinaface\")\n",
    "objRecognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematical metrics for analizing facial similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity is 0.35477153678865364\n",
      "Euclidean distance is 3.8419692767006404\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import euclidean,cosine\n",
    "\n",
    "#Obtain the analysis of the image\n",
    "embedding1=DeepFace.represent(img_path=\"single2.jpeg\",model_name=\"ArcFace\", detector_backend=\"retinaface\")\n",
    "embedding2=DeepFace.represent(img_path=\"single11.jpeg\",model_name=\"ArcFace\", detector_backend=\"retinaface\")\n",
    "\n",
    "#Extract the multi-dimensional vector only\n",
    "embedding1Vector1=np.array(embedding1[0][\"embedding\"])\n",
    "embedding1Vector2=embedding2[0][\"embedding\"]\n",
    "\n",
    "def cosine_similarity(embedding1, embedding2):\n",
    "    dot_product = np.dot(embedding1, embedding2)\n",
    "    norm1 = np.linalg.norm(embedding1)\n",
    "    norm2 = np.linalg.norm(embedding2)\n",
    "    similarity = dot_product / (norm1 * norm2)\n",
    "    return similarity\n",
    "\n",
    "print(\"Cosine similarity is \"+ str(cosine_similarity(embedding1Vector1,embedding1Vector2)))\n",
    "\n",
    "def euclidean_distance(embedding1,embedding2):\n",
    "    return euclidean(embedding1,embedding2)\n",
    "\n",
    "print(\"Euclidean distance is \"+ str(euclidean_distance(embedding1Vector1,embedding1Vector2)))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
